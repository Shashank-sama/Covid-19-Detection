{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.11 64-bit ('MPF': conda)"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.11"
    },
    "colab": {
      "name": "Frontal Lateral.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU",
    "interpreter": {
      "hash": "3dd217612e3efbc53bda62975acccf69dc94b7f474970d20d9b0bbb03e9d7037"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "outputs": [],
      "metadata": {
        "id": "hVjUSVTjPxMp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d85e9f74-4c2e-4ba3-8067-990277cb3537"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import tensorflow as tf\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "from tensorflow.keras.models import Model\r\n",
        "from tensorflow.keras.callbacks import CSVLogger\r\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D\r\n",
        "\r\n",
        "from sklearn.metrics import confusion_matrix\r\n",
        "from sklearn.metrics import accuracy_score\r\n",
        "from sklearn.metrics import f1_score\r\n",
        "from sklearn.metrics import recall_score\r\n",
        "from sklearn.metrics import precision_score\r\n",
        "from sklearn.metrics import classification_report\r\n",
        "\r\n",
        "from utils.preprocess import *\r\n",
        "from utils.metrics import *"
      ],
      "outputs": [],
      "metadata": {
        "id": "94Enuf8mPfPG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Covid DATA"
      ],
      "metadata": {
        "id": "B0TdusKIQagH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "X_train_F = np.load('X_train_COVID_1CH.npy')\r\n",
        "X_dev_F = np.load('X_dev_COVID_1CH.npy')\r\n",
        "X_test_F = np.load('X_test_COVID_1CH.npy')\r\n",
        "X_L = np.load('X_test_lateral.npy')\r\n",
        "X_N_O = np.load('X_Covid_neg.npy')"
      ],
      "outputs": [],
      "metadata": {
        "id": "PzS4d27kR1Tz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "X_train_L,X_test_L,X_dev_L = np.array_split(X_L,[375,611])"
      ],
      "outputs": [],
      "metadata": {
        "id": "gba0GgQN75pe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "y_train_F=np.array([[1,0]]*len(X_train_F))\r\n",
        "y_dev_F=np.array([[1,0]]*len(X_dev_F))\r\n",
        "y_test_F=np.array([[1,0]]*len(X_test_F))\r\n",
        "\r\n",
        "y_train_L=np.array([[0,1]]*len(X_train_L))\r\n",
        "y_dev_L=np.array([[0,1]]*len(X_dev_L))\r\n",
        "y_test_L=np.array([[0,1]]*len(X_test_L))\r\n",
        "\r\n",
        "X_train=np.concatenate((X_train_F,X_train_L))\r\n",
        "X_dev=np.concatenate((X_dev_F,X_dev_L))\r\n",
        "X_test=np.concatenate((X_test_F,X_test_L))\r\n",
        "y_train=np.concatenate((y_train_F,y_train_L))\r\n",
        "y_dev=np.concatenate((y_dev_F,y_dev_L))\r\n",
        "y_test=np.concatenate((y_test_F,y_test_L))"
      ],
      "outputs": [],
      "metadata": {
        "id": "teVkPfr-aYw5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "X_train=min_max_preprocessing(X_train)\r\n",
        "X_dev=min_max_preprocessing(X_dev)\r\n",
        "X_test=min_max_preprocessing(X_test)\r\n",
        "X_N = min_max_preprocessing(X_N_O)"
      ],
      "outputs": [],
      "metadata": {
        "id": "63YDnDO1Y_Ji"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "X_train,mean,std=samplewise_preprocessing(X_train)\r\n",
        "X_dev=featurewise_preprocessing(X_dev,mean,std)\r\n",
        "X_test=featurewise_preprocessing(X_test,mean,std)\r\n",
        "X_N = featurewise_preprocessing(X_N,mean,std)"
      ],
      "outputs": [],
      "metadata": {
        "id": "Ym38Yofir1y3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelo\n"
      ],
      "metadata": {
        "id": "PAIYSNDFPfPd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "VGG19 Gray-scale\n"
      ],
      "metadata": {
        "id": "4-kUkdlSn0eW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def get_model_VGG19_gray():\r\n",
        "      model = tf.keras.applications.VGG19(weights='imagenet', include_top=False)\r\n",
        "\r\n",
        "      # Block1_conv1 weights are of the format [3, 3, 3, 64] -> this is for RGB images\r\n",
        "      # For grayscale, format should be [3, 3, 1, 64]. Weighted average of the features has to be calculated across channels.\r\n",
        "      # RGB weights: Red 0.2989, Green 0.5870, Blue 0.1140\r\n",
        "\r\n",
        "      # getting weights of block1 conv1.\r\n",
        "      block1_conv1 = model.get_layer('block1_conv1').get_weights()\r\n",
        "      weights, biases = block1_conv1\r\n",
        "\r\n",
        "      # :weights shape = [3, 3, 3, 64] - (0, 1, 2, 3)\r\n",
        "      # convert :weights shape to = [64, 3, 3, 3] - (3, 2, 0, 1)\r\n",
        "      weights = np.transpose(weights, (3, 2, 0, 1))\r\n",
        "\r\n",
        "\r\n",
        "      kernel_out_channels, kernel_in_channels, kernel_rows, kernel_columns = weights.shape\r\n",
        "\r\n",
        "      # Dimensions : [kernel_out_channels, 1 (since grayscale), kernel_rows, kernel_columns]\r\n",
        "      grayscale_weights = np.zeros((kernel_out_channels, 1, kernel_rows, kernel_columns))\r\n",
        "\r\n",
        "      # iterate out_channels number of times\r\n",
        "      for i in range(kernel_out_channels):\r\n",
        "\r\n",
        "        # get kernel for every out_channel\r\n",
        "        get_kernel = weights[i, :, :, :]\r\n",
        "\r\n",
        "        temp_kernel = np.zeros((3, 3))\r\n",
        "\r\n",
        "        # :get_kernel shape = [3, 3, 3]\r\n",
        "        # axis, dims = (0, in_channel), (1, row), (2, col)\r\n",
        "\r\n",
        "        # calculate weighted average across channel axis\r\n",
        "        in_channels, in_rows, in_columns = get_kernel.shape\r\n",
        "\r\n",
        "        for in_row in range(in_rows):\r\n",
        "          for in_col in range(in_columns):\r\n",
        "            feature_red = get_kernel[0, in_row, in_col]\r\n",
        "            feature_green = get_kernel[1, in_row, in_col]\r\n",
        "            feature_blue = get_kernel[2, in_row, in_col]\r\n",
        "\r\n",
        "            # weighted average for RGB filter\r\n",
        "            total = (feature_red * 0.2989) + (feature_green * 0.5870) + (feature_blue * 0.1140)\r\n",
        "\r\n",
        "            temp_kernel[in_row, in_col] = total\r\n",
        "\r\n",
        "\r\n",
        "        # :temp_kernel is a 3x3 matrix [rows x columns]\r\n",
        "        # add an axis at the end to specify in_channel as 1\r\n",
        "\r\n",
        "        # Second: Add axis at the start of :temp_kernel to make its shape: [1, 3, 3] which is [in_channel, rows, columns]\r\n",
        "        temp_kernel = np.expand_dims(temp_kernel, axis=0)\r\n",
        "\r\n",
        "        # Now, :temp_kernel shape is [1, 3, 3]\r\n",
        "\r\n",
        "        # Concat :temp_kernel to :grayscale_weights along axis=0\r\n",
        "        grayscale_weights[i, :, :, :] = temp_kernel\r\n",
        "\r\n",
        "      # Dimension of :grayscale_weights is [64, 1, 3, 3]\r\n",
        "      # In order to bring it to tensorflow or keras weight format, transpose :grayscale_weights\r\n",
        "\r\n",
        "      # dimension, axis of :grayscale_weights = (out_channels: 0), (in_channels: 1), (rows: 2), (columns: 3)\r\n",
        "      # tf format of weights = (rows: 0), (columns: 1), (in_channels: 2), (out_channels: 3)\r\n",
        "\r\n",
        "      # Go from (0, 1, 2, 3) to (2, 3, 1, 0)\r\n",
        "      grayscale_weights = np.transpose(grayscale_weights, (2, 3, 1, 0)) # (3, 3, 1, 64)\r\n",
        "\r\n",
        "      # combine :grayscale_weights and :biases\r\n",
        "      new_block1_conv1 = [grayscale_weights, biases]\r\n",
        "\r\n",
        "\r\n",
        "      # Reconstruct the layers of VGG16 but replace block1_conv1 weights with :grayscale_weights\r\n",
        "\r\n",
        "      # get weights of all the layers starting from 'block1_conv2'\r\n",
        "      vgg19_weights = {}\r\n",
        "      for layer in model.layers[2:]:\r\n",
        "        if \"conv\" in layer.name:\r\n",
        "          vgg19_weights[\"224_\" + layer.name] = model.get_layer(layer.name).get_weights()\r\n",
        "\r\n",
        "      del model\r\n",
        "\r\n",
        "\r\n",
        "      # Custom build VGG19\r\n",
        "      input = Input(shape=(224, 224, 1), name='224_input')\r\n",
        "      # Block 1\r\n",
        "      x = Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(224, 224, 1), data_format=\"channels_last\", name='224_block1_conv1')(input)\r\n",
        "      x = Conv2D(64, (3, 3), activation='relu', padding='same', name='224_block1_conv2')(x)\r\n",
        "      x = MaxPooling2D((2, 2), strides=(2, 2), name='224_block1_pool')(x)\r\n",
        "\r\n",
        "      # Block 2\r\n",
        "      x = Conv2D(128, (3, 3), activation='relu', padding='same', name='224_block2_conv1')(x)\r\n",
        "      x = Conv2D(128, (3, 3), activation='relu', padding='same', name='224_block2_conv2')(x)\r\n",
        "      x = MaxPooling2D((2, 2), strides=(2, 2), name='224_block2_pool')(x)\r\n",
        "\r\n",
        "      # Block 3\r\n",
        "      x = Conv2D(256, (3, 3), activation='relu', padding='same', name='224_block3_conv1')(x)\r\n",
        "      x = Conv2D(256, (3, 3), activation='relu', padding='same', name='224_block3_conv2')(x)\r\n",
        "      x = Conv2D(256, (3, 3), activation='relu', padding='same', name='224_block3_conv3')(x)\r\n",
        "      x = Conv2D(256, (3, 3), activation='relu', padding='same', name='224_block3_conv4')(x)\r\n",
        "      x = MaxPooling2D((2, 2), strides=(2, 2), name='224_block3_pool')(x)\r\n",
        "\r\n",
        "      # Block 4\r\n",
        "      x = Conv2D(512, (3, 3), activation='relu', padding='same', name='224_block4_conv1')(x)\r\n",
        "      x = Conv2D(512, (3, 3), activation='relu', padding='same', name='224_block4_conv2')(x)\r\n",
        "      x = Conv2D(512, (3, 3), activation='relu', padding='same', name='224_block4_conv3')(x)\r\n",
        "      x = Conv2D(512, (3, 3), activation='relu', padding='same', name='224_block4_conv4')(x)\r\n",
        "      x = MaxPooling2D((2, 2), strides=(2, 2), name='224_block4_pool')(x)\r\n",
        "\r\n",
        "      # Block 5\r\n",
        "      x = Conv2D(512, (3, 3), activation='relu', padding='same', name='224_block5_conv1')(x)\r\n",
        "      x = Conv2D(512, (3, 3), activation='relu', padding='same', name='224_block5_conv2')(x)\r\n",
        "      x = Conv2D(512, (3, 3), activation='relu', padding='same', name='224_block5_conv3')(x)\r\n",
        "      x = Conv2D(512, (3, 3), activation='relu', padding='same', name='224_block5_conv4')(x)\r\n",
        "      x = MaxPooling2D((8, 8), strides=(8, 8), name='224_block5_pool')(x)\r\n",
        "\r\n",
        "      base_model = Model(inputs=input, outputs=x)\r\n",
        "\r\n",
        "      base_model.get_layer('224_block1_conv1').set_weights(new_block1_conv1)\r\n",
        "      for layer in base_model.layers[2:]:\r\n",
        "        if 'conv' in layer.name:\r\n",
        "          base_model.get_layer(layer.name).set_weights(vgg19_weights[layer.name])\r\n",
        "\r\n",
        "      x = base_model.output\r\n",
        "\r\n",
        "      for layer in base_model.layers:\r\n",
        "          layer.trainable = True\r\n",
        "\r\n",
        "      x = tf.keras.layers.GlobalAveragePooling2D()(x)  \r\n",
        "      layers = tf.keras.layers.Flatten()(x)\r\n",
        "      #layers = tf.keras.layers.Dense(128,activation=\"relu\")(layers)\r\n",
        "      layers = tf.keras.layers.Dropout(0.2)(layers)\r\n",
        "      layers = tf.keras.layers.Dense(1024 ,activation=\"relu\")(layers)\r\n",
        "      layers = tf.keras.layers.Dropout(0.2)(layers)\r\n",
        "      layers = tf.keras.layers.Dense( 512,activation=\"relu\")(layers)\r\n",
        "      layers = tf.keras.layers.Dense( 64,activation=\"relu\")(layers)\r\n",
        "      predictions = tf.keras.layers.Dense(2, activation=\"softmax\", name=\"output_1\")(layers)\r\n",
        "\r\n",
        "      #Compilador\r\n",
        "      model = tf.keras.Model(inputs = base_model.input, outputs=predictions)\r\n",
        "      optimizer=tf.keras.optimizers.Adam(lr=0.0001) \r\n",
        "      model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=['accuracy'])\r\n",
        "      model.summary()\r\n",
        "      return model"
      ],
      "outputs": [],
      "metadata": {
        "id": "xuCaO8w7zI4A"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "model = get_model_VGG19_gray()"
      ],
      "outputs": [],
      "metadata": {
        "scrolled": true,
        "id": "ztMJRc8FPfPs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3afb43cd-65b9-49f5-93d5-de598efb813d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "model_name='VGG16_For_Covid_FyL'\r\n",
        "log_dir=\"logs/\"\r\n",
        "filepath = log_dir+\"Saved_models/\"+model_name+\".h5\"\r\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath, monitor='val_accuracy', save_best_only=True, mode='max')\r\n",
        "csv_logger = CSVLogger('logs/csv/'+model_name+'.csv', append=False, separator=';')\r\n",
        "history=model.fit(X_train, y_train, epochs=30, batch_size=64, validation_data=(X_dev, y_dev),callbacks=[csv_logger,checkpoint])"
      ],
      "outputs": [],
      "metadata": {
        "id": "BtpNX72fPfPx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e3e782d-7be4-46b2-9edc-eedc3c5cd71f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "plt.figure()\r\n",
        "plt.plot(g['accuracy'])\r\n",
        "plt.plot(g['val_accuracy'])\r\n",
        "plt.title('model loss')\r\n",
        "plt.xlabel('Epoch')\r\n",
        "plt.ylabel('Accuracy')\r\n",
        "plt.legend(['train', 'validation'], loc='upper left')"
      ],
      "outputs": [],
      "metadata": {
        "id": "dSJMdFjlK9_o",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "0b4175f7-b3f4-492d-d0b4-23a67154bd3c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "plt.figure()\r\n",
        "plt.plot(g['loss'])\r\n",
        "plt.plot(g['val_loss'])\r\n",
        "plt.title('model loss')\r\n",
        "plt.xlabel('Epoch')\r\n",
        "plt.ylabel('Loss')\r\n",
        "plt.legend(['train', 'validation'], loc='upper left')"
      ],
      "outputs": [],
      "metadata": {
        "id": "SalTgOSwK36S",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "ba7fee68-7e42-438c-f8e4-556ebd6020cf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Metricas VGG16"
      ],
      "metadata": {
        "id": "UUYW0H8BA-qa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "model.load_weights('logs/Saved_models/VGG19_For_Covid_FyL.h5')"
      ],
      "outputs": [],
      "metadata": {
        "id": "XhenKPihBX9f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "predictions=model.predict(X_test)\r\n",
        "y_pred_bool = np.argmax(predictions, axis=-1)"
      ],
      "outputs": [],
      "metadata": {
        "id": "B7PUgiIhsYED"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "y_hat=np.argmax(y_test,axis=-1)\r\n",
        "metrics(y_hat,y_pred_bool)"
      ],
      "outputs": [],
      "metadata": {
        "id": "SxB2aIAPmVfz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 639
        },
        "outputId": "eb9c4f02-5b48-4725-c47e-06365f95a192"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "images_filename = 'X_neg_F_2.npy'\r\n",
        "np.save(images_filename, X_neg_F)\r\n",
        "images_filename = 'X_neg_F_ind_2.npy'\r\n",
        "np.save(images_filename, X_neg_F_ind)\r\n",
        "images_filename = 'X_neg_L_2.npy'\r\n",
        "np.save(images_filename, X_neg_L)"
      ],
      "outputs": [],
      "metadata": {
        "id": "Y-R3v269rC4c"
      }
    }
  ]
}