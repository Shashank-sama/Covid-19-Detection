{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "CNN_Application_on_COVID-19_Detection.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "yAZk87VrO6p8",
        "kvGT_H-dnwoS",
        "qcC_uTK9UJKg",
        "5KWEP-OcQ4TN",
        "gUeSXwOgooJP",
        "u0A0T75SaPBH",
        "KoGh6rp8oy4p",
        "8mVe0npgUM7G"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Libraries"
      ],
      "metadata": {
        "id": "yAZk87VrO6p8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/drive') "
      ],
      "metadata": {
        "id": "ybPzyKNjO-J3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pafL7Li0jyXW"
      },
      "source": [
        "from scipy import misc, ndimage, signal\n",
        "import numpy \n",
        "import numpy as np\n",
        "import random \n",
        "import ntpath\n",
        "import os\n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors as colors\n",
        "from keras import optimizers \n",
        "from keras import regularizers\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "from tensorflow.keras import backend\n",
        "from keras.layers import Lambda, Layer\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, LSTM\n",
        "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, GlobalAveragePooling2D, UpSampling2D\n",
        "from keras.layers.core import Reshape\n",
        "from keras import optimizers\n",
        "from keras.utils import np_utils\n",
        "from keras import backend as K\n",
        "from keras import regularizers\n",
        "from time import time\n",
        "from keras.models import load_model\n",
        "import keras\n",
        "import datetime\n",
        "from keras import backend as K\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers.convolutional import Convolution2D, MaxPooling2D,AveragePooling2D\n",
        "from keras.metrics import categorical_crossentropy\n",
        "from keras import optimizers \n",
        "from keras import regularizers\n",
        "from keras.layers import Lambda, Layer\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, LSTM\n",
        "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, GlobalAveragePooling2D, UpSampling2D\n",
        "from keras.initializers import Constant, RandomNormal, glorot_normal\n",
        "from keras.layers.core import Reshape\n",
        "from keras import optimizers\n",
        "from keras.utils import np_utils\n",
        "from keras import backend as K\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras.callbacks import TensorBoard\n",
        "from time import time\n",
        "from random import randint\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import random\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from numpy import *\n",
        "from PIL import Image\n",
        "import matplotlib\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors as colors\n",
        "import tensorflow as tf\n",
        "import sys\n",
        "import glob\n",
        "from scipy import misc, ndimage, signal\n",
        "import numpy\n",
        "import random\n",
        "import ntpath\n",
        "import skimage\n",
        "from skimage.util.shape import view_as_blocks, view_as_windows\n",
        "import tensorflow as tf\n",
        "from tensorflow import clip_by_value\n",
        "import sys\n",
        "import glob\n",
        "from scipy import misc, ndimage, signal\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors as colors\n",
        "from keras import optimizers \n",
        "from keras import regularizers\n",
        "from keras.layers import Lambda, Layer\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, LSTM, ReLU\n",
        "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, GlobalAveragePooling2D, UpSampling2D\n",
        "from keras.layers.core import Reshape\n",
        "from keras.utils import np_utils\n",
        "from keras import backend as K\n",
        "import pandas as pd\n",
        "from tensorflow import clip_by_value\n",
        "import time as tm\n",
        "from tensorflow.keras.layers import Concatenate, Lambda\n",
        "import numpy as np\n",
        "import time\n",
        "import time as tm\n",
        "from yellowbrick.classifier import ClassificationReport\n",
        "from yellowbrick.classifier import ClassPredictionError\n",
        "from yellowbrick.classifier import ConfusionMatrix\n",
        "from yellowbrick.classifier import ROCAUC\n",
        "from yellowbrick.classifier import PrecisionRecallCurve\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "from sklearn.metrics import hamming_loss\n",
        "from sklearn.metrics import log_loss\n",
        "from sklearn.metrics import zero_one_loss\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "import tensorflow as tf\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.base import BaseEstimator\n",
        "import keras\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, Dropout\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kvGT_H-dnwoS"
      },
      "source": [
        "# Loading database"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0Qe-YY986vu"
      },
      "source": [
        "X_train_N = np.load('.../Seed#/X_Neg_Train_224_Seed2.npy')\n",
        "X_train_P = np.load('.../Seed#/X_Pos_Train_224_Seed2.npy')\n",
        "\n",
        "X_test_N = np.load('.../Seed#/X_Neg_Test_224_Seed2.npy')\n",
        "X_test_P = np.load('.../Seed#/X_Pos_Test_224_Seed2.npy') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxjz0Fb9rL43"
      },
      "source": [
        "y_train_N=np.array([[1,0]]*len(X_train_N))\n",
        "y_test_N =np.array([[1,0]]*len(X_test_N))\n",
        "\n",
        "y_train_P=np.array([[0,1]]*len(X_train_P))\n",
        "y_test_P =np.array([[0,1]]*len(X_test_P))\n",
        "\n",
        "X_train=np.concatenate((X_train_N,X_train_P))\n",
        "X_test =np.concatenate((X_test_N,X_test_P))\n",
        "y_train=np.concatenate((y_train_N,y_train_P))\n",
        "y_test =np.concatenate((y_test_N,y_test_P)) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_N.shape, y_train_P.shape "
      ],
      "metadata": {
        "id": "0PLNW-A-I-xi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_N.shape, y_test_P.shape "
      ],
      "metadata": {
        "id": "X0EZKxGRJFBe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNhDbtCR3yxr"
      },
      "source": [
        "X_train.shape "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNNsox5FJySA"
      },
      "source": [
        "X_test.shape "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_5nJlBUTnAR"
      },
      "source": [
        "print(X_train.min(),X_test.min())\n",
        "print(X_train.max(),X_test.max()) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wi7IsaMGs3re"
      },
      "source": [
        "print(X_train.shape[0],X_train_N.shape[0],X_train_P.shape[0]) \n",
        "print(X_test.shape[0], X_test_N.shape[0], X_test_P.shape[0]) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qcC_uTK9UJKg"
      },
      "source": [
        "# Functions used to preprocess the data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WrBuctEaCj2h"
      },
      "source": [
        "def samplewise_preprocessing(images,labels):\n",
        "    filtered_labels=[]\n",
        "    processed_images = []\n",
        "    means = []\n",
        "    stds = []\n",
        "    for i in range(images.shape[0]):\n",
        "        mean = np.mean(images[i]) \n",
        "        std = np.std(images[i]) \n",
        "        if std!=0 and mean != 0:\n",
        "            means.append(mean)\n",
        "            stds.append(std)\n",
        "            processed_images.append((images[i]-mean)/std)\n",
        "            filtered_labels.append(labels[i])\n",
        "    \n",
        "    return np.array(processed_images),np.array(filtered_labels), np.mean(means), np.mean(stds)\n",
        "\n",
        "def featurewise_preprocessing(images, mean, std):\n",
        "    processed_images = np.zeros_like(images, dtype=np.float32)\n",
        "    for i in range(images.shape[0]):\n",
        "        processed_images[i] = (images[i]-mean)/std\n",
        "    return processed_images\n",
        "\n",
        "def min_max_preprocessing(images,labels):\n",
        "    filtered_labels=[]\n",
        "    processed_images = []\n",
        "    for i in range(len(images)):\n",
        "        maxi=np.max(images[i])\n",
        "        mini=np.min(images[i])\n",
        "        if maxi-mini != 0:\n",
        "          processed_images.append((images[i]-mini)/(maxi-mini))\n",
        "          filtered_labels.append(labels[i])\n",
        "    return np.array(processed_images),np.array(filtered_labels)\n",
        "\n",
        "def convert_n_CH(train_images,test_images,mode='gray'):\n",
        "    if mode=='gray':\n",
        "        converted_train=np.expand_dims(train_images,axis=3)\n",
        "        converted_test=np.expand_dims(test_images,axis=3)\n",
        "    elif mode=='rgb':\n",
        "        converted_train=np.array([cv2.cvtColor(img,cv2.COLOR_GRAY2BGR) for img in train_images])\n",
        "        converted_test=np.array([cv2.cvtColor(img,cv2.COLOR_GRAY2BGR) for img in test_images])\n",
        "\n",
        "    return converted_train,converted_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Functions used to evaluate the models"
      ],
      "metadata": {
        "id": "5KWEP-OcQ4TN"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "do2e_5ODykqU"
      },
      "source": [
        "def metrics(Y_true,predictions):\n",
        "    \"\"\"\n",
        "    Function to print the performance metrics.\n",
        "\n",
        "    Inputs\n",
        "    Y_true: Ground truth labels\n",
        "    predictions: Predicted labels\n",
        "\n",
        "    Outputs\n",
        "    Accuracy, F1 Score, Recall, Precision, Classification report, Confusion matrix\n",
        "    \"\"\"\n",
        "\n",
        "    print('Accuracy:', accuracy_score(Y_true, predictions))\n",
        "    print('F1 score:', f1_score(Y_true, predictions,average='weighted'))\n",
        "    print('Recall:', recall_score(Y_true, predictions,average='weighted'))\n",
        "    print('Precision:', precision_score(Y_true, predictions, average='weighted'))\n",
        "    print('\\n Clasification report:\\n', classification_report(Y_true, predictions))\n",
        "    print('\\n Confusion matrix:\\n',confusion_matrix(Y_true, predictions))\n",
        "\n",
        "    snn_cm = confusion_matrix(Y_true, predictions)\n",
        "    snn_df_cm = pd.DataFrame(snn_cm, range(2), range(2))  \n",
        "    plt.figure(figsize = (9,5))  \n",
        "    sn.set(font_scale=1.4)\n",
        "    sn.heatmap(snn_df_cm, annot=True, annot_kws={\"size\": 12}, fmt=\"d\")  \n",
        "    plt.show()  \n",
        "\n",
        "def metrics_1(model,X_test,y_test):\n",
        "    predictions=model.predict(X_test)\n",
        "    predictions = np.argmax(predictions, axis=-1)\n",
        "    y_test=np.argmax(y_test,axis=-1)\n",
        "    print('Accuracy:', accuracy_score(y_test, predictions))\n",
        "    print('F1 score:', f1_score(y_test, predictions))\n",
        "    print('Recall:', recall_score(y_test, predictions))\n",
        "    print('Precision:', precision_score(y_test, predictions))\n",
        "    print('\\n clasification report:\\n', classification_report(y_test, predictions))\n",
        "    print('\\n confusion matrix:\\n',confusion_matrix(y_test, predictions))\n",
        "    print(\"Verdaderos positivos:\",get_true_pos(y_test,predictions))\n",
        "    print(\"Verdaderos negativos:\",get_true_neg(y_test,predictions))\n",
        "    print(\"Falsos negativos:\",get_false_neg(y_test,predictions))\n",
        "    print(\"Falsos Positivos:\",get_false_pos(y_test,predictions))\n",
        "    print(\"Sensibilidad:\",get_sensitivity(y_test,predictions))\n",
        "    print(\"Especificidad:\",get_specificity(y_test,predictions))\n",
        "\n",
        "def get_true_pos(y, pred, th=0.5):\n",
        "\n",
        "    \"\"\"\n",
        "    Function to calculate the total of true positive (TP) predictions.\n",
        "    \n",
        "    Inputs\n",
        "    y: Ground truth labels\n",
        "    pred: Predicted labels\n",
        "    th: Classification threshold\n",
        "    \"\"\"\n",
        "\n",
        "    pred_t = (pred > th)\n",
        "    return np.sum((pred_t == True) & (y == 1))\n",
        "\n",
        "def get_true_neg(y, pred, th=0.5):\n",
        "\n",
        "    \"\"\"\n",
        "    Function to calculate the total of true negative (TN) predictions.\n",
        "    \n",
        "    Inputs\n",
        "    y: Ground truth labels\n",
        "    pred: Predicted labels\n",
        "    th: Classification threshold\n",
        "    \"\"\"\n",
        "\n",
        "    pred_t = (pred > th)\n",
        "    return np.sum((pred_t == False) & (y == 0))\n",
        "\n",
        "def get_false_neg(y, pred, th=0.5):\n",
        "\n",
        "    \"\"\"\n",
        "    Function to calculate the total of false negative (FN) predictions.\n",
        "    \n",
        "    Inputs\n",
        "    y: Ground truth labels\n",
        "    pred: Predicted labels\n",
        "    th: Classification threshold\n",
        "    \"\"\"\n",
        "    \n",
        "    pred_t = (pred > th)\n",
        "    return np.sum((pred_t == False) & (y == 1))\n",
        "\n",
        "def get_false_pos(y, pred, th=0.5):\n",
        "\n",
        "    \"\"\"\n",
        "    Function to calculate the total of false positive (FP) predictions.\n",
        "    \n",
        "    Inputs\n",
        "    y: Ground truth labels\n",
        "    pred: Predicted labels\n",
        "    th: Classification threshold\n",
        "    \"\"\"\n",
        "\n",
        "    pred_t = (pred > th)\n",
        "    return np.sum((pred_t == True) & (y == 0))\n",
        "\n",
        "def print_confidence_intervals(class_labels, statistics):\n",
        "\n",
        "    \"\"\"\n",
        "    Function to calculate the confidence interval (5%-95%).\n",
        "    \n",
        "    Inputs\n",
        "    class_labels: List with class names\n",
        "    statistics: \n",
        "\n",
        "    Outputs\n",
        "    Returns DataFrame with confidence intervals for each class\n",
        "    \"\"\"\n",
        "\n",
        "    df = pd.DataFrame(columns=[\"Mean AUC (CI 5%-95%)\"])\n",
        "    for i in range(len(class_labels)):\n",
        "        mean = statistics.mean(axis=1)[i]\n",
        "        max_ = np.quantile(statistics, .95, axis=1)[i]\n",
        "        min_ = np.quantile(statistics, .05, axis=1)[i]\n",
        "        df.loc[class_labels[i]] = [\"%.2f (%.2f-%.2f)\" % (mean, min_, max_)]\n",
        "    return df\n",
        "\n",
        "def get_roc_curve(gt, pred, target_names):\n",
        "\n",
        "    \"\"\"\n",
        "    Function to plot the ROC curve.\n",
        "    \n",
        "    Inputs\n",
        "    gt: Ground truth labels\n",
        "    pred: Predicted labels\n",
        "    target_names: List with class names \n",
        "    \"\"\"\n",
        "\n",
        "    for i in range(len(target_names)):\n",
        "        auc_roc = roc_auc_score(gt[:, i], pred[:, i])\n",
        "        label = target_names[i] + \" AUC: %.3f \" % auc_roc\n",
        "        xlabel = \"False positive rate\"\n",
        "        ylabel = \"True positive rate\"\n",
        "        a, b, _ = roc_curve(gt[:, i], pred[:, i])\n",
        "        plt.figure(1, figsize=(7, 7))\n",
        "        plt.plot([0, 1], [0, 1], 'k--')\n",
        "        plt.plot(a, b, label=label)\n",
        "        plt.xlabel(xlabel)\n",
        "        plt.ylabel(ylabel)\n",
        "        plt.legend(loc='upper center', bbox_to_anchor=(1.3, 1), fancybox=True, ncol=1)\n",
        "\n",
        "def plot_calibration_curve(y, pred,class_labels):\n",
        "\n",
        "    \"\"\"\n",
        "    Function to plot the calibration curve.\n",
        "    \n",
        "    Inputs\n",
        "    y: Ground truth labels\n",
        "    pred: Predicted labels\n",
        "    class_labels: List with class names \n",
        "    \"\"\"\n",
        "\n",
        "    plt.figure(figsize=(20, 20))\n",
        "    for i in range(len(class_labels)):\n",
        "        plt.subplot(4, 4, i + 1)\n",
        "        fraction_of_positives, mean_predicted_value = calibration_curve(y[:,i], pred[:,i], n_bins=20)\n",
        "        plt.plot([0, 1], [0, 1], linestyle='--')\n",
        "        plt.plot(mean_predicted_value, fraction_of_positives, marker='.')\n",
        "        plt.xlabel(\"Predicted Value\")\n",
        "        plt.ylabel(\"Fraction of Positives\")\n",
        "        plt.title(class_labels[i])\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def get_accuracy(y, pred, th=0.5):\n",
        "\n",
        "    \"\"\"\n",
        "    Function to calculate the accuracy.\n",
        "    \n",
        "    Inputs\n",
        "    y: Ground truth labels\n",
        "    pred: Predicted labels\n",
        "    th: Classification threshold\n",
        "    \"\"\"\n",
        "\n",
        "    accuracy = 0.0\n",
        "    TP = get_true_pos(y, pred, th)\n",
        "    FP = get_false_pos(y, pred, th)\n",
        "    TN = get_true_neg(y, pred, th)\n",
        "    FN = get_false_pos(y, pred, th)\n",
        "    accuracy = (TP+TN)/(TP+TN+FP+FN)\n",
        "    return accuracy\n",
        "\n",
        "def get_sensitivity(y, pred, th=0.5):\n",
        "\n",
        "    \"\"\"\n",
        "    Function to calculate the sensitivity.\n",
        "    \n",
        "    Inputs\n",
        "    y: Ground truth labels\n",
        "    pred: Predicted labels\n",
        "    th: Classification threshold\n",
        "    \"\"\"\n",
        "\n",
        "    sensitivity = 0.0\n",
        "    TP = get_true_pos(y,pred,th)\n",
        "    FN = get_false_neg(y,pred,th)\n",
        "    sensitivity = TP/(TP+FN)\n",
        "    return sensitivity\n",
        "\n",
        "def get_specificity(y, pred, th=0.5):\n",
        "\n",
        "    \"\"\"\n",
        "    Function to calculate the specificity.\n",
        "    \n",
        "    Inputs\n",
        "    y: Ground truth labels\n",
        "    pred: Predicted labels\n",
        "    th: Classification threshold\n",
        "    \"\"\"\n",
        "    \n",
        "    specificity = 0.0\n",
        "    TN = get_true_neg(y,pred,th)\n",
        "    FP = get_false_pos(y,pred,th)\n",
        "    specificity = TN/(TN+FP)\n",
        "    return specificity "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUeSXwOgooJP"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukPWWdy-htrg"
      },
      "source": [
        "print(X_train.shape) \n",
        "print(X_test.shape) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVn5afCjVALE"
      },
      "source": [
        "print(X_train.min(),X_test.min())\n",
        "print(X_train.max(),X_test.max())\n",
        "print(X_train.shape,X_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_, y_train_ = min_max_preprocessing(X_train, y_train)\n",
        "X_test_, y_test_ = min_max_preprocessing(X_test, y_test) "
      ],
      "metadata": {
        "id": "Lb8YEZyHvTeq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train_.min(),X_test_.min())\n",
        "print(X_train_.max(),X_test_.max())\n",
        "print(X_train_.shape,X_test_.shape)  \n",
        "print(y_train_.shape,y_test_.shape) "
      ],
      "metadata": {
        "id": "1yShQDb4J1_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train_\n",
        "X_test  = X_test_\n",
        "y_train = y_train_\n",
        "y_test  = y_test_ "
      ],
      "metadata": {
        "id": "Bq_tKgwGvWa2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0A0T75SaPBH"
      },
      "source": [
        "# TPU init"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGof1a8xaRXK"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "print(\"Tensorflow version \" + tf.__version__)\n",
        "\n",
        "try:\n",
        "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
        "  print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
        "except ValueError:\n",
        "  raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n",
        "\n",
        "tf.config.experimental_connect_to_cluster(tpu)\n",
        "tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "tpu_strategy = tf.distribute.TPUStrategy(tpu) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KoGh6rp8oy4p"
      },
      "source": [
        "# Functions used to define and work with models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFk3vM_YC3xj"
      },
      "source": [
        "###############################################VGG16###############################################\n",
        "def vgg16_1canal():\n",
        "    pre_trained_model = tf.keras.applications.VGG16(\n",
        "                    include_top=False,\n",
        "                    weights= 'imagenet',\n",
        "                    input_shape = (224, 224, 3)\n",
        "                    )\n",
        "    for layer in pre_trained_model.layers[:2]: \n",
        "       layer.trainable = False\n",
        "    for layer in pre_trained_model.layers[2:]:\n",
        "       layer.trainable = True\n",
        "\n",
        "    input_tensor = Input(shape=(224,224,1))\n",
        "\n",
        "    x = Conv2D(3,(3,3),padding='same')(input_tensor)    \n",
        "    x = pre_trained_model(x)\n",
        "\n",
        "    x = tf.keras.layers.GlobalAveragePooling2D()(x)  \n",
        "    layers = tf.keras.layers.Flatten()(x)\n",
        "    layers = tf.keras.layers.Dropout(0.2)(layers)\n",
        "    layers = tf.keras.layers.Dense(1024 ,activation=\"relu\")(layers)\n",
        "    layers = tf.keras.layers.Dropout(0.2)(layers)\n",
        "    layers = tf.keras.layers.Dense( 512,activation=\"relu\")(layers)\n",
        "    layers = tf.keras.layers.Dense( 64,activation=\"relu\")(layers)\n",
        "    predictions = tf.keras.layers.Dense(2, activation=\"softmax\", name=\"output_1\")(layers)\n",
        "    #Compilador\n",
        "    model = tf.keras.Model(inputs = input_tensor, outputs=predictions)\n",
        "    optimizer=tf.keras.optimizers.Adam(lr=0.0001) \n",
        "    print(\"Model VGG16 Generated\")\n",
        "    model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "###############################################VGG19###############################################\n",
        "def vgg19_1canal():\n",
        "    pre_trained_model = tf.keras.applications.VGG19(\n",
        "                    include_top=False,\n",
        "                    weights= 'imagenet',\n",
        "                    input_shape = (224, 224, 3)\n",
        "                    )\n",
        "    for layer in pre_trained_model.layers[:4]: \n",
        "       layer.trainable = False\n",
        "    for layer in pre_trained_model.layers[4:]:\n",
        "       layer.trainable = True\n",
        "\n",
        "    input_tensor = Input(shape=(224,224,1))\n",
        "    \n",
        "    x = Conv2D(3,(3,3),padding='same')(input_tensor)    \n",
        "    x = pre_trained_model(x)\n",
        "\n",
        "    x = tf.keras.layers.GlobalAveragePooling2D()(x)  \n",
        "    layers = tf.keras.layers.Flatten()(x)\n",
        "    layers = tf.keras.layers.Dropout(0.2)(layers)\n",
        "    layers = tf.keras.layers.Dense(1024 ,activation=\"relu\")(layers)\n",
        "    layers = tf.keras.layers.Dropout(0.2)(layers)\n",
        "    layers = tf.keras.layers.Dense( 512,activation=\"relu\")(layers)\n",
        "    layers = tf.keras.layers.Dense( 64,activation=\"relu\")(layers)\n",
        "    predictions = tf.keras.layers.Dense(2, activation=\"softmax\", name=\"output_1\")(layers)\n",
        "    #Compilador\n",
        "    model = tf.keras.Model(inputs = input_tensor, outputs=predictions)\n",
        "    optimizer=tf.keras.optimizers.Adam(lr=0.0001) \n",
        "    print(\"Model VGG19 Generated\")\n",
        "    model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "###############################################ResNet50###############################################\n",
        "def resNet50_1canal():\n",
        "    pre_trained_model = tf.keras.applications.ResNet50(\n",
        "                    include_top=False,\n",
        "                    weights= 'imagenet',\n",
        "                    input_shape = (224, 224, 3)\n",
        "                    )\n",
        "    for layer in pre_trained_model.layers[:100]: \n",
        "       layer.trainable = False\n",
        "    for layer in pre_trained_model.layers[100:]:\n",
        "       layer.trainable = True\n",
        "\n",
        "    input_tensor = Input(shape=(224,224,1))\n",
        "    \n",
        "    x = Conv2D(3,(3,3),padding='same')(input_tensor)   \n",
        "    x = pre_trained_model(x)\n",
        "\n",
        "    x = tf.keras.layers.GlobalAveragePooling2D()(x)  \n",
        "    layers = tf.keras.layers.Flatten()(x)\n",
        "    layers = tf.keras.layers.Dropout(0.2)(layers)\n",
        "    layers = tf.keras.layers.Dense(1024 ,activation=\"relu\")(layers)\n",
        "    layers = tf.keras.layers.Dropout(0.2)(layers)\n",
        "    layers = tf.keras.layers.Dense( 512,activation=\"relu\")(layers)\n",
        "    layers = tf.keras.layers.Dense( 64,activation=\"relu\")(layers)\n",
        "    predictions = tf.keras.layers.Dense(2, activation=\"softmax\", name=\"output_1\")(layers)\n",
        "    \n",
        "    #Compilador\n",
        "    model = tf.keras.Model(inputs = input_tensor, outputs=predictions)\n",
        "    optimizer=tf.keras.optimizers.Adam(lr=0.0001) \n",
        "    print(\"Model ResNet50 Generated\")\n",
        "    model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "###############################################ResNet152V2###############################################\n",
        "def ResNet152V2_1canal():\n",
        "    pre_trained_model = tf.keras.applications.ResNet152V2(\n",
        "                    include_top=False,\n",
        "                    weights= 'imagenet',\n",
        "                    input_shape = (224, 224, 3)\n",
        "                    )\n",
        "    for layer in pre_trained_model.layers[:4]: \n",
        "       layer.trainable = False\n",
        "    for layer in pre_trained_model.layers[4:]:\n",
        "       layer.trainable = True\n",
        "\n",
        "    input_tensor = Input(shape=(224,224,1))\n",
        "    \n",
        "    x = Conv2D(3,(3,3),padding='same')(input_tensor)   \n",
        "    x = pre_trained_model(x)\n",
        "\n",
        "    x = tf.keras.layers.GlobalAveragePooling2D()(x)  \n",
        "    layers = tf.keras.layers.Flatten()(x)\n",
        "    layers = tf.keras.layers.Dropout(0.2)(layers)\n",
        "    layers = tf.keras.layers.Dense(1024 ,activation=\"relu\")(layers)\n",
        "    layers = tf.keras.layers.Dropout(0.2)(layers)\n",
        "    layers = tf.keras.layers.Dense( 512,activation=\"relu\")(layers)\n",
        "    layers = tf.keras.layers.Dense( 64,activation=\"relu\")(layers)\n",
        "    predictions = tf.keras.layers.Dense(2, activation=\"softmax\", name=\"output_1\")(layers)\n",
        "    \n",
        "    #Compilador\n",
        "    model = tf.keras.Model(inputs = input_tensor, outputs=predictions)\n",
        "    optimizer=tf.keras.optimizers.Adam(lr=0.0001) \n",
        "    print(\"Model ResNet152V2 Generated\")\n",
        "    model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "###############################################InceptionV3###############################################\n",
        "def InceptionV3_1canal():\n",
        "    pre_trained_model = tf.keras.applications.InceptionV3(\n",
        "                    include_top=False,\n",
        "                    weights= 'imagenet',\n",
        "                    input_shape = (224, 224, 3)\n",
        "                    )\n",
        "    for layer in pre_trained_model.layers[:4]: \n",
        "       layer.trainable = False\n",
        "    for layer in pre_trained_model.layers[4:]:\n",
        "       layer.trainable = True\n",
        "\n",
        "    input_tensor = Input(shape=(224,224,1))\n",
        "    \n",
        "    x = Conv2D(3,(3,3),padding='same')(input_tensor)   \n",
        "    x = pre_trained_model(x)\n",
        "\n",
        "    x = tf.keras.layers.GlobalAveragePooling2D()(x)  \n",
        "    layers = tf.keras.layers.Flatten()(x)\n",
        "    layers = tf.keras.layers.Dropout(0.2)(layers)\n",
        "    layers = tf.keras.layers.Dense(1024 ,activation=\"relu\")(layers)\n",
        "    layers = tf.keras.layers.Dropout(0.2)(layers)\n",
        "    layers = tf.keras.layers.Dense( 512,activation=\"relu\")(layers)\n",
        "    layers = tf.keras.layers.Dense( 64,activation=\"relu\")(layers)\n",
        "    predictions = tf.keras.layers.Dense(2, activation=\"softmax\", name=\"output_1\")(layers)\n",
        "    \n",
        "    #Compilador\n",
        "    model = tf.keras.Model(inputs = input_tensor, outputs=predictions)\n",
        "    optimizer=tf.keras.optimizers.Adam(lr=0.0001) \n",
        "    print(\"Model InceptionV3 Generated\")\n",
        "    model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=['accuracy'])\n",
        "    return model\n",
        "    \n",
        "\n",
        "###############################################InceptionResNetV2###############################################\n",
        "def InceptionResnetV2_1canal():\n",
        "    pre_trained_model = tf.keras.applications.InceptionResNetV2(\n",
        "                    include_top=False,\n",
        "                    weights= 'imagenet',\n",
        "                    input_shape = (224, 224, 3)\n",
        "                    )\n",
        "    for layer in pre_trained_model.layers[:180]: \n",
        "       layer.trainable = False\n",
        "    for layer in pre_trained_model.layers[180:]:\n",
        "       layer.trainable = True\n",
        "\n",
        "    input_tensor = Input(shape=(224,224,1))\n",
        "\n",
        "    x = Conv2D(3,(3,3),padding='same')(input_tensor)    \n",
        "    x = pre_trained_model(x)\n",
        "\n",
        "    x = tf.keras.layers.GlobalAveragePooling2D()(x)  \n",
        "    layers = tf.keras.layers.Flatten()(x)\n",
        "    layers = tf.keras.layers.Dropout(0.2)(layers)\n",
        "    layers = tf.keras.layers.Dense(1024 ,activation=\"relu\")(layers)\n",
        "    layers = tf.keras.layers.Dropout(0.2)(layers)\n",
        "    layers = tf.keras.layers.Dense( 512,activation=\"relu\")(layers)\n",
        "    layers = tf.keras.layers.Dense( 64,activation=\"relu\")(layers)\n",
        "    predictions = tf.keras.layers.Dense(2, activation=\"softmax\", name=\"output_1\")(layers)\n",
        "    \n",
        "    model = tf.keras.Model(inputs = input_tensor, outputs=predictions)\n",
        "    optimizer=tf.keras.optimizers.Adam(lr=0.0001) \n",
        "    print(\"Model InceptionResNetV2 Generated\")\n",
        "    model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "###############################################MobileNetV2###############################################\n",
        "def MobileNetV2_1canal():\n",
        "    pre_trained_model = tf.keras.applications.MobileNetV2(\n",
        "                    include_top=False,\n",
        "                    weights= 'imagenet',\n",
        "                    input_shape = (224, 224, 3)\n",
        "                    )\n",
        "    for layer in pre_trained_model.layers[:180]: \n",
        "       layer.trainable = False\n",
        "    for layer in pre_trained_model.layers[180:]:\n",
        "       layer.trainable = True\n",
        "\n",
        "    input_tensor = Input(shape=(224,224,1))\n",
        "    \n",
        "    x = Conv2D(3,(3,3),padding='same')(input_tensor)    \n",
        "    x = pre_trained_model(x)\n",
        "\n",
        "    x = tf.keras.layers.GlobalAveragePooling2D()(x)  \n",
        "    layers = tf.keras.layers.Flatten()(x)\n",
        "    layers = tf.keras.layers.Dropout(0.2)(layers)\n",
        "    layers = tf.keras.layers.Dense(1024 ,activation=\"relu\")(layers)\n",
        "    layers = tf.keras.layers.Dropout(0.2)(layers)\n",
        "    layers = tf.keras.layers.Dense( 512,activation=\"relu\")(layers)\n",
        "    layers = tf.keras.layers.Dense( 64,activation=\"relu\")(layers)\n",
        "    predictions = tf.keras.layers.Dense(2, activation=\"softmax\", name=\"output_1\")(layers)\n",
        "    \n",
        "    #Compilador\n",
        "    model = tf.keras.Model(inputs = input_tensor, outputs=predictions)\n",
        "    optimizer=tf.keras.optimizers.Adam(lr=0.0001) \n",
        "    print(\"Model MobileNetV2 Generated\")\n",
        "    model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "###############################################DenseNet201###############################################\n",
        "def DenseNet201_1canal():\n",
        "    pre_trained_model = tf.keras.applications.DenseNet201(\n",
        "                    include_top=False,\n",
        "                    weights= 'imagenet',\n",
        "                    input_shape = (224, 224, 3)\n",
        "                    )\n",
        "    for layer in pre_trained_model.layers[:180]: \n",
        "       layer.trainable = False\n",
        "    for layer in pre_trained_model.layers[180:]:\n",
        "       layer.trainable = True\n",
        "\n",
        "    input_tensor = Input(shape=(224,224,1))\n",
        "    \n",
        "    x = Conv2D(3,(3,3),padding='same')(input_tensor)    \n",
        "    x = pre_trained_model(x)\n",
        "\n",
        "    x = tf.keras.layers.GlobalAveragePooling2D()(x)  \n",
        "    layers = tf.keras.layers.Flatten()(x)\n",
        "    layers = tf.keras.layers.Dropout(0.2)(layers)\n",
        "    layers = tf.keras.layers.Dense(1024 ,activation=\"relu\")(layers)\n",
        "    layers = tf.keras.layers.Dropout(0.2)(layers)\n",
        "    layers = tf.keras.layers.Dense( 512,activation=\"relu\")(layers)\n",
        "    layers = tf.keras.layers.Dense( 64,activation=\"relu\")(layers)\n",
        "    predictions = tf.keras.layers.Dense(2, activation=\"softmax\", name=\"output_1\")(layers)\n",
        "    \n",
        "    model = tf.keras.Model(inputs = input_tensor, outputs=predictions)\n",
        "    optimizer=tf.keras.optimizers.Adam(lr=0.0001) \n",
        "    print(\"Model DenseNet201 Generated\")\n",
        "    model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "###############################################NASNetMobile###############################################\n",
        "def NASNetMobile_1canal():\n",
        "    pre_trained_model = tf.keras.applications.NASNetMobile(\n",
        "                    include_top=False,\n",
        "                    weights= 'imagenet',\n",
        "                    input_shape = (224, 224, 3)\n",
        "                    )\n",
        "    for layer in pre_trained_model.layers[:180]: \n",
        "       layer.trainable = False\n",
        "    for layer in pre_trained_model.layers[180:]:\n",
        "       layer.trainable = True\n",
        "\n",
        "    input_tensor = Input(shape=(224, 224,1))\n",
        "    \n",
        "    x = Conv2D(3,(3,3),padding='same')(input_tensor)   \n",
        "    x = pre_trained_model(x)\n",
        "\n",
        "    x = tf.keras.layers.GlobalAveragePooling2D()(x)  \n",
        "    layers = tf.keras.layers.Flatten()(x)\n",
        "    layers = tf.keras.layers.Dropout(0.2)(layers)\n",
        "    layers = tf.keras.layers.Dense(1024 ,activation=\"relu\")(layers)\n",
        "    layers = tf.keras.layers.Dropout(0.2)(layers)\n",
        "    layers = tf.keras.layers.Dense( 512,activation=\"relu\")(layers)\n",
        "    layers = tf.keras.layers.Dense( 64,activation=\"relu\")(layers)\n",
        "    predictions = tf.keras.layers.Dense(2, activation=\"softmax\", name=\"output_1\")(layers)\n",
        "\n",
        "    model = tf.keras.Model(inputs = input_tensor, outputs=predictions)\n",
        "    optimizer=tf.keras.optimizers.Adam(lr=0.0001) \n",
        "    print(\"Model NASNetMobile Generated\")\n",
        "    model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=['accuracy'])\n",
        "    return model "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grpvUwQqaakO"
      },
      "source": [
        "def Final_Results_Test(PATH_trained_models,model_):\n",
        "    global AccTest\n",
        "    global LossTest\n",
        "    AccTest = []\n",
        "    LossTest= [] \n",
        "    B_accuracy = 0 \n",
        "    for filename in sorted(os.listdir(PATH_trained_models)):\n",
        "        if filename != ('train') and filename != ('validation'):\n",
        "            print(filename)\n",
        "            with tpu_strategy.scope(): \n",
        "                 _model = model_\n",
        "            _model.load_weights(PATH_trained_models+'/'+filename)\n",
        "            loss,accuracy = _model.evaluate(X_test, y_test, verbose=0)\n",
        "            print(f'Loss={loss:.4f} y Accuracy={accuracy:0.4f}'+'\\n')\n",
        "\n",
        "            BandAccTest  = accuracy\n",
        "            BandLossTest = loss\n",
        "            AccTest.append(BandAccTest)    \n",
        "            LossTest.append(BandLossTest)  \n",
        "            \n",
        "            if accuracy > B_accuracy:\n",
        "                B_accuracy = accuracy\n",
        "                B_loss = loss\n",
        "                B_name = filename\n",
        "    \n",
        "    print(\"\\n\\nBest\")\n",
        "    print(B_name)\n",
        "    print(f'Loss={B_loss:.4f} y Accuracy={B_accuracy:0.4f}'+'\\n')\n",
        "    return PATH_trained_models+'/'+B_name\n",
        "\n",
        "def Final_Results_Train(PATH_trained_models,model_):\n",
        "    global AccTrain\n",
        "    global LossTrain\n",
        "    AccTrain = []\n",
        "    LossTrain = [] \n",
        "    B_accuracy = 0 \n",
        "    for filename in sorted(os.listdir(PATH_trained_models)):\n",
        "        if filename != ('train') and filename != ('validation'):\n",
        "            print(filename)\n",
        "            with tpu_strategy.scope(): \n",
        "                 _model = model_\n",
        "            _model.load_weights(PATH_trained_models+'/'+filename)\n",
        "            loss,accuracy = _model.evaluate(X_train, y_train, verbose=0)\n",
        "            print(f'Loss={loss:.4f} y Accuracy={accuracy:0.4f}'+'\\n')\n",
        "\n",
        "            BandAccTrain  = accuracy\n",
        "            BandLossTrain = loss\n",
        "            AccTrain.append(BandAccTrain)    \n",
        "            LossTrain.append(BandLossTrain)  \n",
        "            \n",
        "            if accuracy > B_accuracy:\n",
        "                B_accuracy = accuracy\n",
        "                B_loss = loss\n",
        "                B_name = filename\n",
        "    \n",
        "    print(\"\\n\\nBest\")\n",
        "    print(B_name)\n",
        "    print(f'Loss={B_loss:.4f} y Accuracy={B_accuracy:0.4f}'+'\\n')\n",
        "\n",
        "def graphics(AccTest, AccTrain, LossTest, LossTrain, model_name, path_img_base, model_):\n",
        "    if not os.path.exists(path_img_base+\"/\"+model_name):\n",
        "       os.makedirs(path_img_base+\"/\"+model_name)\n",
        "    with tpu_strategy.scope():  \n",
        "        model = model_\n",
        "    \n",
        "    lossTEST,accuracyTEST   = model.evaluate(X_test, y_test,verbose=None)\n",
        "    lossTRAIN,accuracyTRAIN = model.evaluate(X_train, y_train,verbose=None)\n",
        "    \n",
        "    with plt.style.context('seaborn-white'):\n",
        "        plt.figure(figsize=(10, 10))\n",
        "        plt.plot(np.concatenate([np.array([accuracyTRAIN]),np.array(AccTrain)],axis=0))\n",
        "        plt.plot(np.concatenate([np.array([accuracyTEST]),np.array(AccTest)],axis=0)) #Test\n",
        "        plt.title('Accuracy Vs Epoch')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.legend(['Train', 'Test'], loc='upper left')\n",
        "        plt.grid('on')\n",
        "        plt.savefig(path_img_base+'/'+model_name+'/Accuracy_'+model_name+'.eps', format='eps')\n",
        "        plt.savefig(path_img_base+'/'+model_name+'/Accuracy_'+model_name+'.svg', format='svg')\n",
        "        plt.savefig(path_img_base+'/'+model_name+'/Accuracy_'+model_name+'.pdf', format='pdf')     \n",
        "        plt.show()\n",
        "        \n",
        "        plt.figure(figsize=(10, 10))\n",
        "        plt.plot(np.concatenate([np.array([lossTRAIN]),np.array(LossTrain)],axis=0))\n",
        "        plt.plot(np.concatenate([np.array([lossTEST]),np.array(LossTest)],axis=0)) #Test\n",
        "        plt.title('Loss Vs Epoch')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.legend(['Train', 'Test'], loc='upper left')\n",
        "        plt.grid('on')\n",
        "        plt.savefig(path_img_base+'/'+model_name+'/Loss_'+model_name+'.eps', format='eps')\n",
        "        plt.savefig(path_img_base+'/'+model_name+'/Loss_'+model_name+'.svg', format='svg')\n",
        "        plt.savefig(path_img_base+'/'+model_name+'/Loss_'+model_name+'.pdf', format='pdf') \n",
        "        plt.show()\n",
        "\n",
        "def trainTPU(path_model, epochs, model_Name, m_selected=\"VGG16\"):\n",
        "    global model_name\n",
        "    start_time = tm.time()\n",
        "    model_name = model_Name\n",
        "    path_log_base = path_model+'/'+model_Name\n",
        "    if not os.path.exists(path_log_base):\n",
        "        os.makedirs(path_log_base)\n",
        "\n",
        "    with tpu_strategy.scope():\n",
        "      if m_selected == \"VGG16\":\n",
        "        model = vgg16_1canal()\n",
        "      elif m_selected == \"VGG19\":\n",
        "        model = vgg19_1canal()\n",
        "      elif m_selected == \"ResNet50\":\n",
        "        model = resNet50_1canal()\n",
        "      elif m_selected == \"ResNet152V2\":\n",
        "        model = ResNet152V2_1canal()\n",
        "      elif m_selected == \"InceptionV3\":\n",
        "        model = InceptionV3_1canal()\n",
        "      elif m_selected == \"InceptionResnetV2\":\n",
        "        model = InceptionResnetV2_1canal()\n",
        "      elif m_selected == \"MobileNetV2\":\n",
        "        model = MobileNetV2_1canal()\n",
        "      elif m_selected == \"DenseNet201\":\n",
        "        model = DenseNet201_1canal()\n",
        "      else:\n",
        "        model = NASNetMobile_1canal()\n",
        "\n",
        "    epoch_ = 1\n",
        "    for epoch in range(epochs):\n",
        "        epoch=epoch+1\n",
        "        print(\"epoch \",epoch)\n",
        "        model.fit(X_train,y_train,validation_data=(X_test,y_test), batch_size=64*4, epochs=epoch_, verbose=1) \n",
        "        model.save_weights(path_model+'/'+model_name+'/'+str(epoch).zfill(4)+'.hdf5', overwrite=True) \n",
        "\n",
        "    TIME = tm.time() - start_time\n",
        "    print(\"Time \"+model_name+\" = %s [seconds]\" % TIME) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import backend as K\n",
        "\n",
        "def dice_coef(y_true, y_pred):\n",
        "  smooth = 1\n",
        "  intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n",
        "  return (2. * intersection + smooth) / (K.sum(K.square(y_true),-1) + K.sum(K.square(y_pred),-1) + smooth)\n",
        "\n",
        "def dice_coef_loss(y_true, y_pred):\n",
        "  return 1-dice_coef(y_true, y_pred)\n",
        "\n",
        "def iou(y_true, y_pred):\n",
        "    def f(y_true, y_pred):\n",
        "        intersection = (y_true * y_pred).sum()\n",
        "        smooth = 1\n",
        "        union = y_true.sum() + y_pred.sum() - intersection\n",
        "        x = (intersection + smooth) / (union + smooth)\n",
        "        x = x.astype(np.float32)\n",
        "        return x\n",
        "    return tf.numpy_function(f, [y_true, y_pred], tf.float32)\n",
        "\n",
        "def bce_dice_loss(y_true, y_pred):\n",
        "    return binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
        "\n",
        "def focal_loss(y_true, y_pred):\n",
        "    alpha=0.25\n",
        "    gamma=2\n",
        "    def focal_loss_with_logits(logits, targets, alpha, gamma, y_pred):\n",
        "        weight_a = alpha * (1 - y_pred) ** gamma * targets\n",
        "        weight_b = (1 - alpha) * y_pred ** gamma * (1 - targets)\n",
        "        return (tf.math.log1p(tf.exp(-tf.abs(logits))) + tf.nn.relu(-logits)) * (weight_a + weight_b) + logits * weight_b\n",
        "\n",
        "    y_pred = tf.clip_by_value(y_pred, tf.keras.backend.epsilon(), 1 - tf.keras.backend.epsilon())\n",
        "    logits = tf.math.log(y_pred / (1 - y_pred))\n",
        "    loss = focal_loss_with_logits(logits=logits, targets=y_true, alpha=alpha, gamma=gamma, y_pred=y_pred)\n",
        "    return tf.reduce_mean(loss) "
      ],
      "metadata": {
        "id": "yIcwbJG8R1n4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Unet_3():\n",
        "  inputs = Input(shape=(224, 224, 1), name='input')\n",
        "\n",
        "  c1 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(inputs)\n",
        "  c1 = tf.keras.layers.Dropout(0.1)(c1)\n",
        "  c1 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c1)\n",
        "  p1 = tf.keras.layers.MaxPooling2D((2, 2))(c1)\n",
        "\n",
        "  c2 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p1)\n",
        "  c2 = tf.keras.layers.Dropout(0.1)(c2)\n",
        "  c2 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c2)\n",
        "  p2 = tf.keras.layers.MaxPooling2D((2, 2))(c2)\n",
        "  \n",
        "  c3 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p2)\n",
        "  c3 = tf.keras.layers.Dropout(0.2)(c3)\n",
        "  c3 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c3)\n",
        "  p3 = tf.keras.layers.MaxPooling2D((2, 2))(c3)\n",
        "  \n",
        "  c4 = tf.keras.layers.Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p3)\n",
        "  c4 = tf.keras.layers.Dropout(0.2)(c4)\n",
        "  c4 = tf.keras.layers.Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c4)\n",
        "  p4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(c4)\n",
        "  \n",
        "  c5 = tf.keras.layers.Conv2D(1024, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p4)\n",
        "  c5 = tf.keras.layers.Dropout(0.3)(c5)\n",
        "  c5 = tf.keras.layers.Conv2D(1024, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c5)\n",
        "\n",
        "  u6 = tf.keras.layers.Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(c5)\n",
        "  u6 = tf.keras.layers.concatenate([u6, c4])\n",
        "  c6 = tf.keras.layers.Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u6)\n",
        "  c6 = tf.keras.layers.Dropout(0.2)(c6)\n",
        "  c6 = tf.keras.layers.Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c6)\n",
        "  \n",
        "  u7 = tf.keras.layers.Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(c6)\n",
        "  u7 = tf.keras.layers.concatenate([u7, c3])\n",
        "  c7 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u7)\n",
        "  c7 = tf.keras.layers.Dropout(0.2)(c7)\n",
        "  c7 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c7)\n",
        "  \n",
        "  u8 = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c7)\n",
        "  u8 = tf.keras.layers.concatenate([u8, c2])\n",
        "  c8 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u8)\n",
        "  c8 = tf.keras.layers.Dropout(0.1)(c8)\n",
        "  c8 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c8)\n",
        "  \n",
        "  u9 = tf.keras.layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c8)\n",
        "  u9 = tf.keras.layers.concatenate([u9, c1], axis=3)\n",
        "  c9 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u9)\n",
        "  c9 = tf.keras.layers.Dropout(0.1)(c9)\n",
        "  c9 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c9)\n",
        "  \n",
        "  outputs = tf.keras.layers.Conv2D(1, (1, 1), activation='sigmoid')(c9)\n",
        "  \n",
        "  model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
        "  print(\"Model U-Net Generated\")\n",
        "  model.compile(optimizer='adam', loss=dice_coef_loss, metrics=['accuracy',dice_coef,iou,]) \n",
        "  return model "
      ],
      "metadata": {
        "id": "0rllpcDfSO40"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SEGmodel = Unet_3()"
      ],
      "metadata": {
        "id": "ukhz486sR19E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SEGmodel.load_weights(\".../Unet_finetune_v3.h5\") "
      ],
      "metadata": {
        "id": "rRmDRkw8Sc7O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape,X_test.shape) "
      ],
      "metadata": {
        "id": "ILHGyggbSgyt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SEGX_train= np.expand_dims(X_train,axis=3)\n",
        "SEGX_test = np.expand_dims(X_test,axis=3)"
      ],
      "metadata": {
        "id": "Gwl61E71Sg03"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(SEGX_train.shape,SEGX_test.shape) "
      ],
      "metadata": {
        "id": "uR1x9UHvS3bY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_masks=SEGmodel.predict(SEGX_train) \n",
        "X_test_masks=SEGmodel.predict(SEGX_test) "
      ],
      "metadata": {
        "id": "H6QS3b9aekTy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_masks=np.round(X_train_masks) \n",
        "X_test_masks=np.round(X_test_masks) "
      ],
      "metadata": {
        "id": "qQQYCt85UP9u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_masks = X_train_masks.astype(np.uint8) \n",
        "X_test_masks = X_test_masks.astype(np.uint8) "
      ],
      "metadata": {
        "id": "GJEtXo6bUX4A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_model = \"./DATA/\"\n",
        "if not os.path.exists(path_model):\n",
        "  os.makedirs(path_model) "
      ],
      "metadata": {
        "id": "BxYrDumMUkVH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.save('./DATA/X_train_masks_seed#',X_train_masks)\n",
        "np.save('./DATA/X_test_masks_seed#',X_test_masks) "
      ],
      "metadata": {
        "id": "zIqP_2eMfM4S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_masks = np.load('./DATA/X_train_masks_seed#.npy')\n",
        "X_test_masks  = np.load('./DATA/X_test_masks_seed#.npy') "
      ],
      "metadata": {
        "id": "va9Rcs8Ie_tu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train*X_train_masks[:,:,:,0]\n",
        "X_test  = X_test*X_test_masks[:,:,:,0] "
      ],
      "metadata": {
        "id": "fmt26aIJUybK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model training and evaluation"
      ],
      "metadata": {
        "id": "8mVe0npgUM7G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path_model = \".../Results/Models\"\n",
        "if not os.path.exists(path_model):\n",
        "  os.makedirs(path_model) "
      ],
      "metadata": {
        "id": "8fMBf0phUydg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_img_base = \".../Results/Figure\"\n",
        "if not os.path.exists(path_img_base):\n",
        "  os.makedirs(path_img_base) "
      ],
      "metadata": {
        "id": "DnNTB0aRUyfx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_Name = \"_InceptionV3\" \n",
        "trainTPU(path_model=path_model, epochs=50, model_Name = model_Name, m_selected=\"InceptionV3\") #Choose one model "
      ],
      "metadata": {
        "id": "tH1vU0KqURSi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_model = \".../Results/Models\"\n",
        "path_img_base = \".../Results/Figure\" "
      ],
      "metadata": {
        "id": "L3szeBokURUu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "M=DenseNet201_1canal()\n",
        "model_Name=\"_InceptionV3\" "
      ],
      "metadata": {
        "id": "mR4Q_S7PURXM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best=Final_Results_Test(path_model+\"/\"+model_Name, M) "
      ],
      "metadata": {
        "id": "y0D7VH14VBCE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=M\n",
        "model.load_weights(best)\n",
        "metrics_1(model,X_test,y_test) "
      ],
      "metadata": {
        "id": "ItMzHHpZVBEl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Final_Results_Train(path_model+\"/\"+model_Name, M) "
      ],
      "metadata": {
        "id": "t5r1CiHMVBG4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graphics(AccTest, AccTrain, LossTest, LossTrain, model_Name, path_img_base, M) "
      ],
      "metadata": {
        "id": "OSd37mwiR5AV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "xTiXGuPeVMM3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}