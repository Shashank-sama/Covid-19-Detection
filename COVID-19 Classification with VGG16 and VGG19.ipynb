{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "COVID19 ",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.10 64-bit ('pDL': conda)"
    },
    "accelerator": "GPU",
    "language_info": {
      "name": "python",
      "version": "3.8.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "interpreter": {
      "hash": "ff370e27a6774bf54cbff1b5ccfbb78e79d3d05163e480422c7cbe67b701680c"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# COVID19 Detection\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4cbgwZWWfWpp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#Import drive files\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "outputs": [],
      "metadata": {
        "id": "tAb77yZ9fzMG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0fdf106-9f29-407d-ae42-d72bce235da7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "%tensorflow_version 2.x #Tensorflow version"
      ],
      "outputs": [],
      "metadata": {
        "id": "pafL7Li0jyXW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e427fba6-be14-4142-bccc-feaf8c46c1bd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!nvidia-smi #GPU"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hUbUS-ziQfRD",
        "outputId": "43c6a96e-ad48-4287-c360-c065c8630256"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Libraries"
      ],
      "metadata": {
        "id": "P1LVLKrONRro"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow.keras import Input, Model\r\n",
        "\r\n",
        "from utils.metrics import *\r\n",
        "from utils.utils import *\r\n",
        "from utils.preprocess import *\r\n",
        "from utils.gradcam import compute_gradcam"
      ],
      "outputs": [],
      "metadata": {
        "id": "1VpD7W7zNMyU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Segmentation models\n",
        "\n",
        "To do the segmentation task it is commonly used the U-Net model"
      ],
      "metadata": {
        "id": "dNaakliz8E2Y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def Unet_3():\r\n",
        "  inputs = Input(shape=(224, 224, 1), name='input')\r\n",
        "  #s = tf.keras.layers.Lambda(lambda x: x / 255)(inputs)\r\n",
        "\r\n",
        "  #Contraction path\r\n",
        "  c1 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(inputs)\r\n",
        "  c1 = tf.keras.layers.Dropout(0.1)(c1)\r\n",
        "  c1 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c1)\r\n",
        "  p1 = tf.keras.layers.MaxPooling2D((2, 2))(c1)\r\n",
        "\r\n",
        "  c2 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p1)\r\n",
        "  c2 = tf.keras.layers.Dropout(0.1)(c2)\r\n",
        "  c2 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c2)\r\n",
        "  p2 = tf.keras.layers.MaxPooling2D((2, 2))(c2)\r\n",
        "  \r\n",
        "  c3 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p2)\r\n",
        "  c3 = tf.keras.layers.Dropout(0.2)(c3)\r\n",
        "  c3 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c3)\r\n",
        "  p3 = tf.keras.layers.MaxPooling2D((2, 2))(c3)\r\n",
        "  \r\n",
        "  c4 = tf.keras.layers.Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p3)\r\n",
        "  c4 = tf.keras.layers.Dropout(0.2)(c4)\r\n",
        "  c4 = tf.keras.layers.Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c4)\r\n",
        "  p4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(c4)\r\n",
        "  \r\n",
        "  c5 = tf.keras.layers.Conv2D(1024, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p4)\r\n",
        "  c5 = tf.keras.layers.Dropout(0.3)(c5)\r\n",
        "  c5 = tf.keras.layers.Conv2D(1024, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c5)\r\n",
        "\r\n",
        "  #Expansive path \r\n",
        "  u6 = tf.keras.layers.Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(c5)\r\n",
        "  u6 = tf.keras.layers.concatenate([u6, c4])\r\n",
        "  c6 = tf.keras.layers.Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u6)\r\n",
        "  c6 = tf.keras.layers.Dropout(0.2)(c6)\r\n",
        "  c6 = tf.keras.layers.Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c6)\r\n",
        "  \r\n",
        "  u7 = tf.keras.layers.Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(c6)\r\n",
        "  u7 = tf.keras.layers.concatenate([u7, c3])\r\n",
        "  c7 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u7)\r\n",
        "  c7 = tf.keras.layers.Dropout(0.2)(c7)\r\n",
        "  c7 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c7)\r\n",
        "  \r\n",
        "  u8 = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c7)\r\n",
        "  u8 = tf.keras.layers.concatenate([u8, c2])\r\n",
        "  c8 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u8)\r\n",
        "  c8 = tf.keras.layers.Dropout(0.1)(c8)\r\n",
        "  c8 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c8)\r\n",
        "  \r\n",
        "  u9 = tf.keras.layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c8)\r\n",
        "  u9 = tf.keras.layers.concatenate([u9, c1], axis=3)\r\n",
        "  c9 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u9)\r\n",
        "  c9 = tf.keras.layers.Dropout(0.1)(c9)\r\n",
        "  c9 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c9)\r\n",
        "  \r\n",
        "  outputs = tf.keras.layers.Conv2D(1, (1, 1), activation='sigmoid')(c9)\r\n",
        "  \r\n",
        "  model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\r\n",
        "  model.compile(optimizer='adam', loss=dice_coef_loss, metrics=['accuracy',dice_coef,iou,])\r\n",
        "  model.summary()\r\n",
        "  return model"
      ],
      "outputs": [],
      "metadata": {
        "id": "W_kAJpEFjVmx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classification models"
      ],
      "metadata": {
        "id": "pDf4NWwTCqnb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#VGG16 for 1-channel images with imagent weights\r\n",
        "\r\n",
        "def get_model_VGG16_gray():\r\n",
        "    model = tf.keras.applications.VGG16(weights='imagenet', include_top=False)\r\n",
        "\r\n",
        "    # Block1_conv1 weights are of the format [3, 3, 3, 64] -> this is for RGB images\r\n",
        "    # For grayscale, format should be [3, 3, 1, 64]. Weighted average of the features has to be calculated across channels.\r\n",
        "    # RGB weights: Red 0.2989, Green 0.5870, Blue 0.1140\r\n",
        "\r\n",
        "    # getting weights of block1 conv1.\r\n",
        "    block1_conv1 = model.get_layer('block1_conv1').get_weights()\r\n",
        "    weights, biases = block1_conv1\r\n",
        "\r\n",
        "    # :weights shape = [3, 3, 3, 64] - (0, 1, 2, 3)\r\n",
        "    # convert :weights shape to = [64, 3, 3, 3] - (3, 2, 0, 1)\r\n",
        "    weights = np.transpose(weights, (3, 2, 0, 1))\r\n",
        "\r\n",
        "\r\n",
        "    kernel_out_channels, kernel_in_channels, kernel_rows, kernel_columns = weights.shape\r\n",
        "\r\n",
        "    # Dimensions : [kernel_out_channels, 1 (since grayscale), kernel_rows, kernel_columns]\r\n",
        "    grayscale_weights = np.zeros((kernel_out_channels, 1, kernel_rows, kernel_columns))\r\n",
        "\r\n",
        "      # iterate out_channels number of times\r\n",
        "    for i in range(kernel_out_channels):\r\n",
        "\r\n",
        "        # get kernel for every out_channel\r\n",
        "        get_kernel = weights[i, :, :, :]\r\n",
        "\r\n",
        "        temp_kernel = np.zeros((3, 3))\r\n",
        "\r\n",
        "        # :get_kernel shape = [3, 3, 3]\r\n",
        "        # axis, dims = (0, in_channel), (1, row), (2, col)\r\n",
        "\r\n",
        "        # calculate weighted average across channel axis\r\n",
        "        in_channels, in_rows, in_columns = get_kernel.shape\r\n",
        "\r\n",
        "        for in_row in range(in_rows):\r\n",
        "            for in_col in range(in_columns):\r\n",
        "                feature_red = get_kernel[0, in_row, in_col]\r\n",
        "                feature_green = get_kernel[1, in_row, in_col]\r\n",
        "                feature_blue = get_kernel[2, in_row, in_col]\r\n",
        "\r\n",
        "            # weighted average for RGB filter\r\n",
        "            total = (feature_red * 0.2989) + (feature_green * 0.5870) + (feature_blue * 0.1140)\r\n",
        "\r\n",
        "            temp_kernel[in_row, in_col] = total\r\n",
        "\r\n",
        "\r\n",
        "        # :temp_kernel is a 3x3 matrix [rows x columns]\r\n",
        "        # add an axis at the end to specify in_channel as 1\r\n",
        "\r\n",
        "        # Second: Add axis at the start of :temp_kernel to make its shape: [1, 3, 3] which is [in_channel, rows, columns]\r\n",
        "        temp_kernel = np.expand_dims(temp_kernel, axis=0)\r\n",
        "\r\n",
        "        # Now, :temp_kernel shape is [1, 3, 3]\r\n",
        "\r\n",
        "        # Concat :temp_kernel to :grayscale_weights along axis=0\r\n",
        "        grayscale_weights[i, :, :, :] = temp_kernel\r\n",
        "\r\n",
        "      # Dimension of :grayscale_weights is [64, 1, 3, 3]\r\n",
        "      # In order to bring it to tensorflow or keras weight format, transpose :grayscale_weights\r\n",
        "\r\n",
        "      # dimension, axis of :grayscale_weights = (out_channels: 0), (in_channels: 1), (rows: 2), (columns: 3)\r\n",
        "      # tf format of weights = (rows: 0), (columns: 1), (in_channels: 2), (out_channels: 3)\r\n",
        "\r\n",
        "      # Go from (0, 1, 2, 3) to (2, 3, 1, 0)\r\n",
        "    grayscale_weights = np.transpose(grayscale_weights, (2, 3, 1, 0)) # (3, 3, 1, 64)\r\n",
        "\r\n",
        "      # combine :grayscale_weights and :biases\r\n",
        "    new_block1_conv1 = [grayscale_weights, biases]\r\n",
        "\r\n",
        "\r\n",
        "      # Reconstruct the layers of VGG16 but replace block1_conv1 weights with :grayscale_weights\r\n",
        "\r\n",
        "      # get weights of all the layers starting from 'block1_conv2'\r\n",
        "    vgg16_weights = {}\r\n",
        "    for layer in model.layers[2:]:\r\n",
        "        if \"conv\" in layer.name:\r\n",
        "            vgg16_weights[\"224_\" + layer.name] = model.get_layer(layer.name).get_weights()\r\n",
        "\r\n",
        "    del model\r\n",
        "\r\n",
        "\r\n",
        "      # Custom build VGG16\r\n",
        "    input = Input(shape=(224, 224, 1), name='224_input')\r\n",
        "      # Block 1\r\n",
        "    x = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(224, 224, 1), data_format=\"channels_last\", name='224_block1_conv1')(input)\r\n",
        "    x = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same', name='224_block1_conv2')(x)\r\n",
        "    x = tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2), name='224_block1_pool')(x)\r\n",
        "\r\n",
        "      # Block 2\r\n",
        "    x = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same', name='224_block2_conv1')(x)\r\n",
        "    x = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same', name='224_block2_conv2')(x)\r\n",
        "    x = tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2), name='224_block2_pool')(x)\r\n",
        "\r\n",
        "      # Block 3\r\n",
        "    x = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same', name='224_block3_conv1')(x)\r\n",
        "    x = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same', name='224_block3_conv2')(x)\r\n",
        "    x = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same', name='224_block3_conv3')(x)\r\n",
        "    x = tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2), name='224_block3_pool')(x)\r\n",
        "\r\n",
        "      # Block 4\r\n",
        "    x = tf.keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same', name='224_block4_conv1')(x)\r\n",
        "    x = tf.keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same', name='224_block4_conv2')(x)\r\n",
        "    x = tf.keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same', name='224_block4_conv3')(x)\r\n",
        "    x = tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2), name='224_block4_pool')(x)\r\n",
        "\r\n",
        "      # Block 5\r\n",
        "    x = tf.keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same', name='224_block5_conv1')(x)\r\n",
        "    x = tf.keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same', name='224_block5_conv2')(x)\r\n",
        "    x = tf.keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same', name='224_block5_conv3')(x)\r\n",
        "    x = tf.keras.layers.MaxPooling2D((8, 8), strides=(8, 8), name='224_block5_pool')(x)\r\n",
        "\r\n",
        "    base_model = Model(inputs=input, outputs=x)\r\n",
        "\r\n",
        "    base_model.get_layer('224_block1_conv1').set_weights(new_block1_conv1)\r\n",
        "    for layer in base_model.layers[2:]:\r\n",
        "        if 'conv' in layer.name:\r\n",
        "            base_model.get_layer(layer.name).set_weights(vgg16_weights[layer.name])\r\n",
        "\r\n",
        "    x = base_model.output\r\n",
        "\r\n",
        "    for layer in base_model.layers:\r\n",
        "        layer.trainable = True\r\n",
        "\r\n",
        "    x = tf.keras.layers.GlobalAveragePooling2D()(x)  \r\n",
        "    layers = tf.keras.layers.Flatten()(x)\r\n",
        "      #layers = tf.keras.layers.Dense(128,activation=\"relu\")(layers)\r\n",
        "    layers = tf.keras.layers.Dropout(0.2)(layers)\r\n",
        "    layers = tf.keras.layers.Dense(1024 ,activation=\"relu\")(layers)\r\n",
        "    layers = tf.keras.layers.Dropout(0.2)(layers)\r\n",
        "    layers = tf.keras.layers.Dense( 512,activation=\"relu\")(layers)\r\n",
        "    layers = tf.keras.layers.Dense( 64,activation=\"relu\")(layers)\r\n",
        "    predictions = tf.keras.layers.Dense(2, activation=\"softmax\", name=\"output_1\")(layers)\r\n",
        "\r\n",
        "      #Compilador\r\n",
        "    model = tf.keras.Model(inputs = base_model.input, outputs=predictions)\r\n",
        "    optimizer=tf.keras.optimizers.Adam(lr=0.0001) \r\n",
        "    loss='categorical_crossentropy'\r\n",
        "    model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\r\n",
        "    model.summary()\r\n",
        "    return model\r\n",
        "##################################################################################################################################################\r\n",
        "\r\n",
        "#VGG19 for 1-channel images with imagent weights\r\n",
        "\r\n",
        "def get_model_VGG19_gray():\r\n",
        "      model = tf.keras.applications.VGG19(weights='imagenet', include_top=False)\r\n",
        "\r\n",
        "      # Block1_conv1 weights are of the format [3, 3, 3, 64] -> this is for RGB images\r\n",
        "      # For grayscale, format should be [3, 3, 1, 64]. Weighted average of the features has to be calculated across channels.\r\n",
        "      # RGB weights: Red 0.2989, Green 0.5870, Blue 0.1140\r\n",
        "\r\n",
        "      # getting weights of block1 conv1.\r\n",
        "      block1_conv1 = model.get_layer('block1_conv1').get_weights()\r\n",
        "      weights, biases = block1_conv1\r\n",
        "\r\n",
        "      # :weights shape = [3, 3, 3, 64] - (0, 1, 2, 3)\r\n",
        "      # convert :weights shape to = [64, 3, 3, 3] - (3, 2, 0, 1)\r\n",
        "      weights = np.transpose(weights, (3, 2, 0, 1))\r\n",
        "\r\n",
        "\r\n",
        "      kernel_out_channels, kernel_in_channels, kernel_rows, kernel_columns = weights.shape\r\n",
        "\r\n",
        "      # Dimensions : [kernel_out_channels, 1 (since grayscale), kernel_rows, kernel_columns]\r\n",
        "      grayscale_weights = np.zeros((kernel_out_channels, 1, kernel_rows, kernel_columns))\r\n",
        "\r\n",
        "      # iterate out_channels number of times\r\n",
        "      for i in range(kernel_out_channels):\r\n",
        "\r\n",
        "        # get kernel for every out_channel\r\n",
        "        get_kernel = weights[i, :, :, :]\r\n",
        "\r\n",
        "        temp_kernel = np.zeros((3, 3))\r\n",
        "\r\n",
        "        # :get_kernel shape = [3, 3, 3]\r\n",
        "        # axis, dims = (0, in_channel), (1, row), (2, col)\r\n",
        "\r\n",
        "        # calculate weighted average across channel axis\r\n",
        "        in_channels, in_rows, in_columns = get_kernel.shape\r\n",
        "\r\n",
        "        for in_row in range(in_rows):\r\n",
        "          for in_col in range(in_columns):\r\n",
        "            feature_red = get_kernel[0, in_row, in_col]\r\n",
        "            feature_green = get_kernel[1, in_row, in_col]\r\n",
        "            feature_blue = get_kernel[2, in_row, in_col]\r\n",
        "\r\n",
        "            # weighted average for RGB filter\r\n",
        "            total = (feature_red * 0.2989) + (feature_green * 0.5870) + (feature_blue * 0.1140)\r\n",
        "\r\n",
        "            temp_kernel[in_row, in_col] = total\r\n",
        "\r\n",
        "\r\n",
        "        # :temp_kernel is a 3x3 matrix [rows x columns]\r\n",
        "        # add an axis at the end to specify in_channel as 1\r\n",
        "\r\n",
        "        # Second: Add axis at the start of :temp_kernel to make its shape: [1, 3, 3] which is [in_channel, rows, columns]\r\n",
        "        temp_kernel = np.expand_dims(temp_kernel, axis=0)\r\n",
        "\r\n",
        "        # Now, :temp_kernel shape is [1, 3, 3]\r\n",
        "\r\n",
        "        # Concat :temp_kernel to :grayscale_weights along axis=0\r\n",
        "        grayscale_weights[i, :, :, :] = temp_kernel\r\n",
        "\r\n",
        "      # Dimension of :grayscale_weights is [64, 1, 3, 3]\r\n",
        "      # In order to bring it to tensorflow or keras weight format, transpose :grayscale_weights\r\n",
        "\r\n",
        "      # dimension, axis of :grayscale_weights = (out_channels: 0), (in_channels: 1), (rows: 2), (columns: 3)\r\n",
        "      # tf format of weights = (rows: 0), (columns: 1), (in_channels: 2), (out_channels: 3)\r\n",
        "\r\n",
        "      # Go from (0, 1, 2, 3) to (2, 3, 1, 0)\r\n",
        "      grayscale_weights = np.transpose(grayscale_weights, (2, 3, 1, 0)) # (3, 3, 1, 64)\r\n",
        "\r\n",
        "      # combine :grayscale_weights and :biases\r\n",
        "      new_block1_conv1 = [grayscale_weights, biases]\r\n",
        "\r\n",
        "\r\n",
        "      # Reconstruct the layers of VGG16 but replace block1_conv1 weights with :grayscale_weights\r\n",
        "\r\n",
        "      # get weights of all the layers starting from 'block1_conv2'\r\n",
        "      vgg19_weights = {}\r\n",
        "      for layer in model.layers[2:]:\r\n",
        "        if \"conv\" in layer.name:\r\n",
        "          vgg19_weights[\"224_\" + layer.name] = model.get_layer(layer.name).get_weights()\r\n",
        "\r\n",
        "      del model\r\n",
        "\r\n",
        "\r\n",
        "      # Custom build VGG19\r\n",
        "      input = Input(shape=(224, 224, 1), name='224_input')\r\n",
        "      # Block 1\r\n",
        "      x = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(224, 224, 1), data_format=\"channels_last\", name='224_block1_conv1')(input)\r\n",
        "      x = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same', name='224_block1_conv2')(x)\r\n",
        "      x = tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2), name='224_block1_pool')(x)\r\n",
        "\r\n",
        "      # Block 2\r\n",
        "      x = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same', name='224_block2_conv1')(x)\r\n",
        "      x = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same', name='224_block2_conv2')(x)\r\n",
        "      x = tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2), name='224_block2_pool')(x)\r\n",
        "\r\n",
        "      # Block 3\r\n",
        "      x = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same', name='224_block3_conv1')(x)\r\n",
        "      x = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same', name='224_block3_conv2')(x)\r\n",
        "      x = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same', name='224_block3_conv3')(x)\r\n",
        "      x = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same', name='224_block3_conv4')(x)\r\n",
        "      x = tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2), name='224_block3_pool')(x)\r\n",
        "\r\n",
        "      # Block 4\r\n",
        "      x = tf.keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same', name='224_block4_conv1')(x)\r\n",
        "      x = tf.keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same', name='224_block4_conv2')(x)\r\n",
        "      x = tf.keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same', name='224_block4_conv3')(x)\r\n",
        "      x = tf.keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same', name='224_block4_conv4')(x)\r\n",
        "      x = tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2), name='224_block4_pool')(x)\r\n",
        "\r\n",
        "      # Block 5\r\n",
        "      x = tf.keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same', name='224_block5_conv1')(x)\r\n",
        "      x = tf.keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same', name='224_block5_conv2')(x)\r\n",
        "      x = tf.keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same', name='224_block5_conv3')(x)\r\n",
        "      x = tf.keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same', name='224_block5_conv4')(x)\r\n",
        "      x = tf.keras.layers.MaxPooling2D((8, 8), strides=(8, 8), name='224_block5_pool')(x)\r\n",
        "\r\n",
        "      base_model = Model(inputs=input, outputs=x)\r\n",
        "\r\n",
        "      base_model.get_layer('224_block1_conv1').set_weights(new_block1_conv1)\r\n",
        "      for layer in base_model.layers[2:]:\r\n",
        "        if 'conv' in layer.name:\r\n",
        "          base_model.get_layer(layer.name).set_weights(vgg19_weights[layer.name])\r\n",
        "\r\n",
        "      x = base_model.output\r\n",
        "\r\n",
        "      for layer in base_model.layers:\r\n",
        "          layer.trainable = True\r\n",
        "\r\n",
        "      x = tf.keras.layers.GlobalAveragePooling2D()(x)  \r\n",
        "      layers = tf.keras.layers.Flatten()(x)\r\n",
        "      #layers = tf.keras.layers.Dense(128,activation=\"relu\")(layers)\r\n",
        "      layers = tf.keras.layers.Dropout(0.2)(layers)\r\n",
        "      layers = tf.keras.layers.Dense(1024 ,activation=\"relu\")(layers)\r\n",
        "      layers = tf.keras.layers.Dropout(0.2)(layers)\r\n",
        "      layers = tf.keras.layers.Dense( 512,activation=\"relu\")(layers)\r\n",
        "      layers = tf.keras.layers.Dense( 64,activation=\"relu\")(layers)\r\n",
        "      predictions = tf.keras.layers.Dense(2, activation=\"softmax\", name=\"output_1\")(layers)\r\n",
        "\r\n",
        "      #Compilador\r\n",
        "      model = tf.keras.Model(inputs = base_model.input, outputs=predictions)\r\n",
        "      optimizer=tf.keras.optimizers.Adam(lr=0.0001) \r\n",
        "      model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=['accuracy'])\r\n",
        "      model.summary()\r\n",
        "      return model"
      ],
      "outputs": [],
      "metadata": {
        "id": "-qRKnElc-0nI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Databases and training\n",
        "\n",
        "The images were saved in npy format, so that the loading of the images is faster and more efficient. \n",
        "\n",
        "The shape is (224,224) in order to apply transfer learning"
      ],
      "metadata": {
        "id": "wqhAVZJrC97_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "PATH='' #Base PATH "
      ],
      "outputs": [],
      "metadata": {
        "id": "RuFMmhusLRi9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Databases for segmentation\n",
        "\n",
        "To train the segmentation models is necessary the image (X) and a binary mask (y)"
      ],
      "metadata": {
        "id": "wSNEYD9WKqXR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "X_train = np.load(PATH+'/DATABASES/SEGMENTATION/X_M+J+N_train.npy')\r\n",
        "X_dev = np.load(PATH+'/DATABASES/SEGMENTATION/X_M+J+N_dev.npy')\r\n",
        "Y_train = np.load(PATH+'/DATABASES/SEGMENTATION/y_M+J+N_train.npy')\r\n",
        "Y_dev = np.load(PATH+'/DATABASES/SEGMENTATION/y_M+J+N_dev.npy')"
      ],
      "outputs": [],
      "metadata": {
        "id": "HLxj2q8JLUiz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "print('Images Shape is:\\nTrain:', X_train.shape,'\\nDev: ',X_dev.shape)\r\n",
        "print('\\nMasks Shape:\\nTrain: ',Y_train.shape,'\\nDev: ',Y_dev.shape)"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g8F6i5lpMZ3b",
        "outputId": "5d5c1b84-d081-4332-88eb-b745adc25f1a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "index=2 #Change to view different images\r\n",
        "\r\n",
        "plt.figure(figsize=(10, 10))\r\n",
        "plt.subplot(121)\r\n",
        "plt.title(\"Original\")\r\n",
        "plt.axis('off')\r\n",
        "plt.imshow(X_train[index], cmap='gray')\r\n",
        "plt.subplot(122)\r\n",
        "plt.title(\"Mask\")\r\n",
        "plt.axis('off')\r\n",
        "plt.imshow(Y_train[index], cmap='gray')\r\n",
        "\r\n",
        "plt.show()"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "id": "rOEv6ItzNiYQ",
        "outputId": "2790bb3d-8e64-48c7-cf8b-fb60a992bf8b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Preprocess"
      ],
      "metadata": {
        "id": "l6QaEi8ZPrvn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#Convert to float32 to avoid error of multiplication\r\n",
        "Y_train = Y_train.astype('float32')\r\n",
        "Y_dev = Y_dev.astype('float32')\r\n",
        "\r\n",
        "#Min-max Normalization\r\n",
        "X_train,Y_train=min_max_preprocessing(X_train,Y_train)\r\n",
        "X_dev,Y_dev=min_max_preprocessing(X_dev,Y_dev)\r\n",
        "\r\n",
        "\r\n",
        "#Z-score Normalization (mean and standard deviation)\r\n",
        "X_train,Y_train,mean,std=samplewise_preprocessing(X_train,Y_train)\r\n",
        "X_dev=featurewise_preprocessing(X_dev,mean,std) # Mean and std of train data is used"
      ],
      "outputs": [],
      "metadata": {
        "id": "BYTk_tmMPu_g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Train segmentation "
      ],
      "metadata": {
        "id": "l-xMZsn3Ot1l"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "model=Unet_3()"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cy5bq0TGO73W",
        "outputId": "99b8fd02-1088-4b5a-99c9-f7ea8b3fe25c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "epochs=3 #Change if you want to train more\r\n",
        "\r\n",
        "history=model.fit(X_train, Y_train, epochs=3, batch_size=32, validation_data=(X_dev, Y_dev)) "
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRleoUbHPCQo",
        "outputId": "4e728f5c-b2b4-4573-b968-5ee446323e3e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "plot_graphs(history,'dice_coef')\r\n",
        "plot_graphs(history,'iou')\r\n",
        "plot_graphs(history,'loss')\r\n",
        "plot_graphs(history,'accuracy')"
      ],
      "outputs": [],
      "metadata": {
        "id": "zDEKpVvwR3NW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Load weights from previous trained model (200 epochs)\r\n",
        "model.load_weights(PATH+'/WEIGHTS/Unet_3_M+J+N_1.h5')"
      ],
      "outputs": [],
      "metadata": {
        "id": "h2zcBK2-SX5L"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#Predict mask\r\n",
        "Pred_Masks = model.predict(X_dev)\r\n",
        "\r\n",
        "#Resize\r\n",
        "pred_img=[]\r\n",
        "for i in Pred_Masks:\r\n",
        "  pred_img.append(np.resize(i,(224,224)))\r\n",
        "\r\n",
        "#Apply binary\r\n",
        "thresh= 0.3\r\n",
        "pred = []\r\n",
        "for a in pred_img:\r\n",
        "  a[a >= thresh] = 1\r\n",
        "  a[a < thresh] = 0\r\n",
        "  pred.append(a)\r\n",
        "\r\n",
        "\r\n",
        "#Multiply masks by the original images\r\n",
        "Seg_imgs=pred*X_dev"
      ],
      "outputs": [],
      "metadata": {
        "id": "j3zI5-W2U86j"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#Plot results\r\n",
        "index=60 #Change to view different images\r\n",
        "\r\n",
        "plt.figure(figsize=(10, 10))\r\n",
        "plt.subplot(141)\r\n",
        "plt.title(\"Original\")\r\n",
        "plt.axis('off')\r\n",
        "plt.imshow(X_dev[index], cmap='gray')\r\n",
        "plt.subplot(142)\r\n",
        "plt.title(\"Real Mask\")\r\n",
        "plt.axis('off')\r\n",
        "plt.imshow(Y_dev[index], cmap='gray')\r\n",
        "plt.subplot(143)\r\n",
        "plt.title(\"Predicted Mask\")\r\n",
        "plt.axis('off')\r\n",
        "plt.imshow(pred[index], cmap='gray')\r\n",
        "plt.subplot(144)\r\n",
        "plt.title(\"Segmented Image\")\r\n",
        "plt.axis('off')\r\n",
        "plt.imshow(Seg_imgs[index], cmap='gray')\r\n",
        "\r\n",
        "plt.show()"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "id": "J5KRSbTIWoLa",
        "outputId": "aadadd12-a895-4e0b-a622-76a3ecdd010d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Databases for classification\n",
        "\n",
        "The data is saved as normal images and also as previously lung-segmented images"
      ],
      "metadata": {
        "id": "PNMVUzm8Kydy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:** Choose if you want train on **Normal Images** or **Segmented Images** and run that cell"
      ],
      "metadata": {
        "id": "nSaX3-MCiYE_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Normal (Without Segmentation)"
      ],
      "metadata": {
        "id": "lmk3TXndDCoI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#Positive COVID19 images\r\n",
        "X_train_P = np.load(PATH+'/DATABASES/POSITIVE/NORMAL/X_pos_train_C.npy')[:1400] #Only a portion of the dataset for the code to run without problem in colab can run.\r\n",
        "X_test_P = np.load(PATH+'/DATABASES/POSITIVE/NORMAL/X_pos_test_C.npy')[:300] #Only a portion of the dataset for the code to run without problem in colab can run.\r\n",
        "X_dev_P = np.load(PATH+'/DATABASES/POSITIVE/NORMAL/X_pos_dev_C.npy')[:300] #Only a portion of the dataset for the code to run without problem in colab can run.\r\n",
        "\r\n",
        "\r\n",
        "#Negative COVID19 images\r\n",
        "X_train_N = np.load(PATH+'/DATABASES/NEGATIVE/NORMAL/X_train_COVID_neg2.npy')[:1400]\r\n",
        "X_test_N = np.load(PATH+'/DATABASES/NEGATIVE/NORMAL/X_test_COVID_neg2.npy')[:300]\r\n",
        "X_dev_N = np.load(PATH+'/DATABASES/NEGATIVE/NORMAL/X_dev_COVID_neg2.npy')[:300]"
      ],
      "outputs": [],
      "metadata": {
        "id": "aSCBcvNgC9q7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Segmented Images"
      ],
      "metadata": {
        "id": "6pEbAK9OiQz9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#Positive COVID19 images\r\n",
        "X_train_P = np.load(PATH+'/DATABASES/POSITIVE/SEGMENTED/X_pos_Seg_Train.npy')[:1400] #Only a portion of the dataset for the code to run without problem in colab can run.\r\n",
        "X_test_P = np.load(PATH+'/DATABASES/POSITIVE/SEGMENTED/X_pos_Seg_Test.npy')[:300] #Only a portion of the dataset for the code to run without problem in colab can run.\r\n",
        "X_dev_P = np.load(PATH+'/DATABASES/POSITIVE/SEGMENTED/X_pos_Seg_Dev.npy')[:300] #Only a portion of the dataset for the code to run without problem in colab can run.\r\n",
        "\r\n",
        "\r\n",
        "#Negative COVID19 images\r\n",
        "X_train_N = np.load(PATH+'/DATABASES/NEGATIVE/SEGMENTED/X_preC_Seg_Train.npy')[:1400]\r\n",
        "X_test_N = np.load(PATH+'/DATABASES/NEGATIVE/SEGMENTED/X_preC_Seg_Test.npy')[:300]\r\n",
        "X_dev_N = np.load(PATH+'/DATABASES/NEGATIVE/SEGMENTED/X_preC_Seg_Dev.npy')[:300]"
      ],
      "outputs": [],
      "metadata": {
        "id": "fcS9gHKBiLBr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Information of the Database"
      ],
      "metadata": {
        "id": "r2mOS3cIjf9b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "print('Positive Images Shape:\\nTrain:',X_train_P.shape,'\\nDev: ',X_dev_P.shape,'\\nTest: ',X_test_P.shape)\r\n",
        "print('\\nNegative Images Shape:\\nTrain:',X_train_N.shape,'\\nDev: ',X_dev_N.shape,'\\nTest: ',X_test_N.shape)"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kq-VMVunbLOw",
        "outputId": "a71bd3f0-ae06-4bee-d1a6-eaf7c2e469e6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "\"\"\"##Preprocess\"\"\" \r\n",
        "\r\n",
        "#Create Labels\r\n",
        "y_train_N=np.array([[1,0]]*len(X_train_N))\r\n",
        "y_dev_N=np.array([[1,0]]*len(X_dev_N))\r\n",
        "y_test_N=np.array([[1,0]]*len(X_test_N))\r\n",
        "\r\n",
        "y_train_P=np.array([[0,1]]*len(X_train_P))\r\n",
        "y_dev_P=np.array([[0,1]]*len(X_dev_P))\r\n",
        "y_test_P=np.array([[0,1]]*len(X_test_P))\r\n",
        "\r\n",
        "\r\n",
        "#Concateneta Positive and Negative\r\n",
        "X_train=np.concatenate((X_train_N,X_train_P))\r\n",
        "X_dev=np.concatenate((X_dev_N,X_dev_P))\r\n",
        "X_test=np.concatenate((X_test_N,X_test_P))\r\n",
        "y_train=np.concatenate((y_train_N,y_train_P))\r\n",
        "y_dev=np.concatenate((y_dev_N,y_dev_P))\r\n",
        "y_test=np.concatenate((y_test_N,y_test_P))\r\n",
        "\r\n",
        "\r\n",
        "#X_train=np.array(X_train,dtype=np.float64)\r\n",
        "#X_dev=np.array(X_dev,dtype=np.float64)\r\n",
        "#X_test=np.array(X_test,dtype=np.float64)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "print('Imagenes entrenamiento: ',len(X_train))\r\n",
        "print('Imagenes validacion: ',len(X_dev))\r\n",
        "print('Imagenes test: ',len(X_test))\r\n",
        "\r\n",
        "#Min_max Normalization\r\n",
        "X_train,y_train=min_max_preprocessing(X_train,y_train)\r\n",
        "X_dev,y_dev=min_max_preprocessing(X_dev,y_dev)\r\n",
        "X_test,y_test=min_max_preprocessing(X_test,y_test)\r\n",
        "\r\n",
        "\r\n",
        "#Z-Score Normalization (mean and std)\r\n",
        "X_train,y_train,mean,std=samplewise_preprocessing(X_train,y_train)\r\n",
        "X_dev=featurewise_preprocessing(X_dev,mean,std)\r\n",
        "X_test=featurewise_preprocessing(X_test,mean,std)\r\n",
        "\r\n",
        "\r\n",
        "#X_train,X_dev,X_test=convert_n_CH(X_train,X_dev,X_test,mode='rgb')\r\n",
        "\r\n",
        "print('Imagenes entrenamiento procesadas: ',len(X_train))\r\n",
        "print('Imagenes validacion procesadas: ',len(X_dev))\r\n",
        "print('Imagenes test procesadas: ',len(X_test))\r\n"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "daXxFfa4aIbW",
        "outputId": "6f0792d0-62e7-4afa-c912-d7970a55bccd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "index=0 #Change to show other images\r\n",
        "\r\n",
        "plt.axis('off')\r\n",
        "plt.imshow(X_train[index], cmap='gray')\r\n",
        "plt.colorbar()\r\n",
        "plt.show()"
      ],
      "outputs": [],
      "metadata": {
        "id": "ZsORssO5jly9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "outputId": "ede534d3-569d-4955-8cb3-63a1c702c422"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Train Classification"
      ],
      "metadata": {
        "id": "Rzwf0pzjhHpu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#Select model - Uncomment the model you want \r\n",
        "model = get_model_VGG19_gray()\r\n",
        "#model= get_model_VGG16_gray"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHkcbabebOnT",
        "outputId": "348d6f80-a000-45d6-9c72-fa33f8c6f25e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "epochs=3 #Change for the number of epochs you want\r\n",
        "\r\n",
        "history=model.fit(X_train, y_train, epochs=epochs, batch_size=64, validation_data=(X_dev, y_dev))"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pGnaPJRYjbZM",
        "outputId": "ccb058b8-ac40-4d6d-e02d-721e7b41fa8a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "plot_graphs(history,'loss')\r\n",
        "plot_graphs(history,'accuracy')"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 543
        },
        "id": "uBT1qCjwkLYA",
        "outputId": "7bdd61bd-49a3-44ac-f39c-7c9ead5ad4b0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the correct weights, it depends of the model (VGG16 or VGG19), and the type of data you trained (Normal or Segmented)\n",
        "\n",
        "**Note: For correct performance it's important to import the whole dataset.**"
      ],
      "metadata": {
        "id": "nM7b7kd7ogxB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#Normal\r\n",
        "#VGG16\r\n",
        "#model.load_weights(PATH+'/WEIGHTS/VGG16_imagenet_posypre_normal.h5')\r\n",
        "#VGG19\r\n",
        "#model.load_weights(PATH+'/WEIGHTS/VGG19_imagenet_posypre_normal.h5')\r\n",
        "\r\n",
        "\r\n",
        "#Segmented\r\n",
        "#VGG16\r\n",
        "#model.load_weights(PATH+'/WEIGHTS/VGG16_imagenet_posypre_seg.h5')\r\n",
        "#VGG19\r\n",
        "model.load_weights(PATH+'/WEIGHTS/VGG19_imagenet_posypre_seg.h5')"
      ],
      "outputs": [],
      "metadata": {
        "id": "F7DPAfhGmNgb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#Metrics of classification\r\n",
        "\r\n",
        "predictions=model.predict(np.expand_dims(X_test,axis=3))\r\n",
        "y_pred_bool = np.argmax(predictions, axis=-1)\r\n",
        "y_hat=np.argmax(y_test,axis=-1)\r\n",
        "\r\n",
        "metrics(y_hat,y_pred_bool)"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "XUOibkFblfCY",
        "outputId": "02cfbd12-fe9e-427c-ea90-d1741fdc2ffb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "tf.compat.v1.disable_eager_execution() #To plot GradCAM (Heatmaps) is necessary to disable eager execution and import the model again\r\n",
        "\r\n",
        "model = get_model_VGG19_gray()\r\n",
        "\r\n",
        "\r\n",
        "#Normal\r\n",
        "#VGG16\r\n",
        "#model.load_weights(PATH+'/WEIGHTS/VGG16_imagenet_posypre_normal.h5')\r\n",
        "#VGG19\r\n",
        "#model.load_weights(PATH+'/WEIGHTS/VGG19_imagenet_posypre_normal.h5')\r\n",
        "\r\n",
        "\r\n",
        "#Segmented\r\n",
        "#VGG16\r\n",
        "#model.load_weights(PATH+'/WEIGHTS/VGG16_imagenet_posypre_seg.h5')\r\n",
        "#VGG19\r\n",
        "model.load_weights(PATH+'/WEIGHTS/VGG19_imagenet_posypre_seg.h5')"
      ],
      "outputs": [],
      "metadata": {
        "id": "hhsPPAHflr9Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15fe5932-3679-4807-c56c-e607a1f395be"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "index=320\r\n",
        "labels=['No-COVID','COVID']\r\n",
        "compute_gradcam(model,np.expand_dims(np.expand_dims(X_test[index], axis=0),axis=3), labels,layer_name='224_block5_conv4')"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "gdlLX5XPlyEC",
        "outputId": "0acffeeb-6046-4c91-a1e9-be8002c7b698"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#ROC Curve\r\n",
        "get_roc_curve(y_test, predictions, labels)"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "Fd5yYpL3l5yo",
        "outputId": "46cfe5b4-67b6-4b68-e345-8e94c28c246f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#Precision Recall Curve\r\n",
        "get_prc_curve(y_test, predictions, labels)"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "Yiuu9-C0l8ea",
        "outputId": "400d16e9-00bf-4f39-80c7-f6b65ca5f321"
      }
    }
  ]
}